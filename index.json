[{"categories":["软件设计模式"],"content":"试用Bridge模式完成下列事情：饮料的杯子有大、中、小；行为有：加奶，加糖，啥都不加。 ","date":"2023-10-31","objectID":"/bridge/:1:0","tags":["设计模式","Java"],"title":"Bridge设计模式","uri":"/bridge/"},{"categories":["软件设计模式"],"content":"Bridge 模式结构 桥机器模式的UML类图如下： Figure 1-1 桥接器类图\r由上图可知，桥接器模式包含以下四个角色： Abstraction（抽象类）：它是用于定义抽象类的接口，通常是抽象类而不是接口，其中定义了一个Implementor（实现类接口）类型的对象并可以维护该对象，它与Implementor之间具有关联关系，它既可以包含抽象业务方法，也可以包含具体业务方法。 RefinedAbstraction（扩充抽象类）：它扩充由Abstraction定义的接口，通常情况下它不再是抽象类而是具体类，实现了在Abstraction中声明的抽象业务方法，在RefinedAbstraction中可以调用在Implementor中定义的业务方法。 Implementor（实现类接口）：它是定义实现类的接口，这个接口不一定要与Abstraction的接口完全一致，事实上这两个接口可以完全不同。一般而言，Implementor接口仅提供基本操作，而Abstraction定义的接口可能会做更多更复杂的操作。Implementor接口对这些基本操作进行了声明，而具体实现交给其子类。通过关联关系，在Abstraction中不仅拥有自己的方法，还可以调用到Implementor中定义的方法，使用关联关系代替继承关系。 ConcreteImplementor（具体实现类）：它具体实现了Implementor接口，在不同的ConcreteImplementor中提供基本操作的不同实现，在程序运行时ConcreteImplementor对象将替换其父类对象，提供给抽象类具体的业务操作方法。 ","date":"2023-10-31","objectID":"/bridge/:1:1","tags":["设计模式","Java"],"title":"Bridge设计模式","uri":"/bridge/"},{"categories":["软件设计模式"],"content":"Bridge 模式实现 Bridge模式的典型代码如下： Implementor public interface Implementor { public void operationImpl(); } ConcreteImplementor public class ConcreteImplementor implements Implementor { public void operationImpl() { //具体业务方法的实现 } } Abstraction public abstract class Abstraction { protected Implementor impl; //定义实现类接口对象 public void setImpl(Implementor impl) { this.impl = impl; } public abstract void operation(); //声明抽象业务方法 } RefinedAbstraction public class RefinedAbstraction extends Abstraction { public void operation() { //业务代码 impl.operationImpl(); //调用实现类的方法 //业务代码 } } ","date":"2023-10-31","objectID":"/bridge/:1:2","tags":["设计模式","Java"],"title":"Bridge设计模式","uri":"/bridge/"},{"categories":["软件设计模式"],"content":"修改Bridge模式的“咖啡”例子 修改后的类图 Figure 1-2 咖啡类图\r修改杯子大小维度 增加小杯具体类，用重复次数来说明是冲中杯还是大杯还是小杯 ，重复1次是小杯。 //小杯 public class SmallCoffee extends Coffee{ public SmallCoffee() { setCoffeeImp(); } public void pourCoffee(){ CoffeeImp coffeeImp = this.getCoffeeImp(); //我们以重复次数来说明是冲中杯还是大杯还是小杯 ,重复1次是小杯 coffeeImp.pourCoffeeImp(); System.out.println(\"小杯来了\" ); } } 修改添加物品维度 增加加糖具体类。 //加糖 public class SugarCoffeeImp extends CoffeeImp{ public void pourCoffeeImp(){ System.out.println(\"加了甜甜的糖浆\"); } } 测试 测试代码： 使用CoffeeImpSingleton可以设定加什么物品，再用定义杯子大小的具体类进行咖啡的设置。 Figure 1-3\r测试结果： Figure 1-4\r","date":"2023-10-31","objectID":"/bridge/:1:3","tags":["设计模式","Java"],"title":"Bridge设计模式","uri":"/bridge/"},{"categories":["软件设计模式"],"content":"修改本例，增加一个新的concrete的Builder。 ","date":"2023-10-31","objectID":"/builder/:1:0","tags":["设计模式","Java"],"title":"Builder设计模式","uri":"/builder/"},{"categories":["软件设计模式"],"content":"Builder 模式结构 建造者模式的UML类图如下： Figure 1-1 Builder类图\r由上图可知，建造者模式包含以下四个角色： Builder（抽象建造者）：它为创建一个产品对象的各个部件指定抽象接口，在该接口中一般声明两类方法，一类方法是buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是getResult()，它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。 ConcreteBuilder（具体建造者）：它实现了Builder接口，实现各个部件的具体构造和装配方法，定义并明确所创建的复杂对象，还可以提供一个方法返回创建好的复杂产品对象（该方法也可以由抽象建造者实现）。 Product（产品）：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。 Director（指挥者）：指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。 ","date":"2023-10-31","objectID":"/builder/:1:1","tags":["设计模式","Java"],"title":"Builder设计模式","uri":"/builder/"},{"categories":["软件设计模式"],"content":"Builder 模式实现 Builder模式的典型代码如下： Product public class Product { private String partA; // 定义部件，部件可以是值类型和引用类型 private String partB; private String partC; // 属性的Getter和Setter方法省略 } Builder public abstract class Builder { // 创建产品对象 protected Product product = new Product(); public abstract void buildPartA(); public abstract void buildPartB(); public abstract void buildPartC(); // 返回产品对象 public Product getResult() { return product; } } ConcreteBuilder public class ConcreteBuilder1 extends Builder { public void buildPartA() { product.setPartA(\"A1\"); } public void buildPartB() { product.setPartA(\"B1\"); } public void buildPartC() { product.setPartA(\"C1\"); } } Director public class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } public void setBuilder(Builder builder) { this.builder = builder; } // 产品的构建与组装方法 public Product construct() { builder.buildPartA(); builder.buildPartB(); builder.buildPartC(); return builder.getResult(); } } ","date":"2023-10-31","objectID":"/builder/:1:2","tags":["设计模式","Java"],"title":"Builder设计模式","uri":"/builder/"},{"categories":["软件设计模式"],"content":"增加一个新的ConcreteBuilder JsonBuilder类 增加一个JsonBuilder的具体建造者，它可以产生一个json格式的文件，其中title设置对象的名称，str设置列表的名称，items设置列表中的内容。 public class JsonBuilder extends Builder { private StringBuffer buffer = new StringBuffer(); // 开始在此属性建立文件 public void makeTitle(String title) { // 一般文字格式的标题 buffer.append(\"\\\"\" + title + \"\\\":\\n{\\n\"); //对象的名称 } public void makeString(String str) { // 一般文字格式的字串 buffer.append(\"\\t\\\"\" + str + \"\\\": [\"); //列表的名称 } public void makeItems(String[] items) { // 一般文字格式的项目 for (int i = 0; i \u003c items.length - 1; i++) {//列表内容 buffer.append(\"\\\"\" + items[i] + \"\\\", \"); } buffer.append(\"\\\"\" + items[items.length - 1] + \"\\\"\"); buffer.append(\"]\\n\"); // 空行 } public Object getResult() { // 完成的文件 buffer.append(\"}\\n\"); return buffer.toString(); // 把StringBuffer转换成String } } 测试类 修改Main测试类，增加Json选项： Figure 1-2\r运行结果： 其中Title为\"Creeting\"在json中被设置为对象名，String为\"从早上到白天结束\"在json中被设置为列表名，Items为\"早安。\",“午安。“在json中被设置为列表内容。 Figure 1-3\r","date":"2023-10-31","objectID":"/builder/:1:3","tags":["设计模式","Java"],"title":"Builder设计模式","uri":"/builder/"},{"categories":["软件设计模式"],"content":"阅读Abstract Factory的例子的代码，举例说明使用Abstract Factory模式的其他应用。 ","date":"2023-10-31","objectID":"/abstract-factory/:1:0","tags":["设计模式","Java"],"title":"Abstract Factory设计模式","uri":"/abstract-factory/"},{"categories":["软件设计模式"],"content":"抽象工厂模式结构 Figure 1-1 抽象工厂模式类图\r由上图可知，抽象工厂模式包含以下四个角色： AbstractProduct（抽象产品）：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法。 Product1（具体产品）：它定义具体工厂生产的具体产品的具体产品对象，实现抽象产品接口中声明的业务方法。 AbstractFactory（抽象工厂）：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。 ConcreteFactory1（具体工厂）：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。 ","date":"2023-10-31","objectID":"/abstract-factory/:1:1","tags":["设计模式","Java"],"title":"Abstract Factory设计模式","uri":"/abstract-factory/"},{"categories":["软件设计模式"],"content":"抽象工厂模式实现 抽象工厂的典型代码如下： AbstractFactory public interface AbstractFactory { public AbstractProduct1 createProduct1(); // 工厂方法一 public AbstractProduct2 createProduct2(); // 工厂方法二 } ConcreteFactory1 public class ConcreteFactory1 implements AbstractFactory { // 工厂方法一 public AbstractProduct1 createProduct1() { return new Product1(); } // 工厂方法二 public AbstractProduct2 createProduct2() { return new Product2(); } } ","date":"2023-10-31","objectID":"/abstract-factory/:1:2","tags":["设计模式","Java"],"title":"Abstract Factory设计模式","uri":"/abstract-factory/"},{"categories":["软件设计模式"],"content":"抽象工厂模式应用 Figure 1-2 抽象工厂\r其中，接口AbstractFactory充当抽象工厂，其子类WindowsFactory、UnixFactory和LinuxFactory充当具体工厂；Text和Button充当抽象产品，其子类WindowsText、UnixText、LinuxText和WindowsButton、UnixButton、LinuxButton充当具体产品。 抽象工厂及其具体工厂 AbstractFactory public abstract class AbstractFactory { //创建Button对象 public abstract Button createButton(); //创建Text对象 public abstract Text createText(); } WindowsFactory public class WindowsFactory extends AbstractFactory { @Override public Button createButton() { return new WindowsButton(); } @Override public Text createText() { return new WindowsText(); } } UnixFactory public class UnixFactory extends AbstractFactory { @Override public Button createButton() { return new UnixButton(); } @Override public Text createText() { return new UnixText(); } } LinuxFactory public class LinuxFactory extends AbstractFactory { @Override public Button createButton() { return new LinuxButton(); } @Override public Text createText() { return new LinuxText(); } } Button抽象类及其具体类 Button抽象类 public abstract class Button{ //点击按钮事件 public abstract void click(); } WindowsButton public class WindowsButton extends Button{ @Override public void click(){ System.out.println(\"点击Windows按钮\"); } } UnixButton public class UnixButton extends Button{ @Override public void click(){ System.out.println(\"点击Unix按钮\"); } } LinuxButton public class LinuxButton extends Button{ @Override public void click(){ System.out.println(\"点击Linux按钮\"); } } 测试函数 测试代码如下： public class Main { public static void main(String[] args) { AbstractFactory factory = new WindowsFactory(); Button button = factory.createButton(); Text text = factory.createText(); button.click(); text.show(); } } 测试结果如下： Figure 1-3\r","date":"2023-10-31","objectID":"/abstract-factory/:1:3","tags":["设计模式","Java"],"title":"Abstract Factory设计模式","uri":"/abstract-factory/"},{"categories":["软件设计模式"],"content":"请举例说明克隆模式的其他应用。 ","date":"2023-10-31","objectID":"/prototype/:1:0","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"应用描述 使用克隆模式实现深克隆： 在图表对象（DataChart）中包含一个数据集对象(DataSet)。数据集对象用于封装要显示的数据，用户可以通过界面上的复制按钮将该图表复制一份，复制后即可得到新的图表对象，然后可以修改新图表的编号、颜色、数据。 ","date":"2023-10-31","objectID":"/prototype/:1:1","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"UML类图 在该设计方案中，DataChart 类包含一个 DataSet 对象，在复制 DataChart 对象的同时将 复制 DataSet 对象，因此需要使用深克隆技术，可使用流来实现深克隆。其中Serializable是java.io包中定义的、用于实现Java类的序列化操作而提供的一个语义级别的接口。Serializable序列化接口没有任何方法或者字段，只是用于标识可序列化的语义。实现了Serializable接口的类可以被ObjectOutputStream转换为字节流，同时也可以通过ObjectInputStream再将其解析为对象。 Figure 1-1 深克隆类图\r","date":"2023-10-31","objectID":"/prototype/:1:2","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"代码实现 DataSet import java.io.Serializable; import java.util.ArrayList; import java.util.List; public class DataSet implements Serializable { private List data = new ArrayList\u003cInteger\u003e(); public List getData() { return data; } public void setData(List data) { this.data = data; } public void addData(int value) { data.add(value); } public Integer getData(int pos) { return (Integer) data.get(pos); } public void removeData(int pos) { data.remove(pos); } public int getLength() { return data.size(); } } DataChart import java.io.*; public class DataChart implements Serializable { /** * ds : 图表数据集 * color : 图表颜色 * no ： 图表编号 */ private DataSet ds = new DataSet(); private String color; private int no; public DataSet getDs() { return ds; } public void setDs(DataSet ds) { this.ds = ds; } public String getColor() { return color; } public void setColor(String color) { this.color = color; } public int getNo() { return no; } public void setNo(int no) { this.no = no; } /** * 打印图表 */ public void display() { System.out.println(\"图表编号：\" + this.getNo()); System.out.println(\"图表颜色：\" + this.getColor()); System.out.println(\"图表数据集\"); for (int i = 0; i \u003c ds.getLength(); ++ i ) { System.out.println(i + \" : \" + ds.getData(i)); } } /** * 使用序列化技术实现深克隆 */ public DataChart deepClone() throws IOException, ClassNotFoundException, OptionalDataException { // 将对象写入流中 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteArrayOutputStream); objectOutputStream.writeObject(this); // 将对象从流中取出 ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(byteArrayOutputStream.toByteArray()); ObjectInputStream objectInputStream = new ObjectInputStream(byteArrayInputStream); return (DataChart) objectInputStream.readObject(); } } 测试代码 import java.util.ArrayList; import java.util.List; public class Client { public static void main(String[] args) { DataChart dataChart1 = null, dataChart2 = null; dataChart1 = new DataChart(); dataChart1.setColor(\"red\"); dataChart1.setNo(1); List data = new ArrayList\u003cInteger\u003e(); data.add(1); data.add(2); DataSet ds = new DataSet(); ds.setData(data); dataChart1.setDs(ds); try { // 调用深克隆方法创建一个克隆对象 dataChart2 = dataChart1.deepClone(); System.out.println(dataChart1 == dataChart2); System.out.println(dataChart1.getDs() == dataChart2.getDs()); System.out.println(dataChart1.getNo() == dataChart2.getNo()); System.out.println(dataChart1.getColor() == dataChart2.getColor()); } catch (Exception e) { System.out.println(\"克隆失败！\"); } } } 测试结果 该结果符合深克隆的引用对象也被复制的现象，因为两个引用对象不相等。 Figure 1-2\r","date":"2023-10-31","objectID":"/prototype/:1:3","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"试描述浅克隆和深克隆。 根据在复制原型对象的同时是否复制包含在原型对象中引用类型的成员变量，原型模式的克隆机制可分为两种，即浅克隆（Shallow Clone）和深克隆（Deep Clone）。 ","date":"2023-10-31","objectID":"/prototype/:2:0","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"浅克隆 在浅克隆中，如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址。简单来说，在浅克隆中，当对象被复制时只复制它本身和其中包含的值类型的成员变量，而引用类型的成员对象并没有复制。 Figure 2-1 浅克隆\r","date":"2023-10-31","objectID":"/prototype/:2:1","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"深克隆 在深克隆中，无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象，深克隆将原型对象的所有引用对象也复制一份给克隆对象。简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。 Figure 2-2 深克隆\r","date":"2023-10-31","objectID":"/prototype/:2:2","tags":["设计模式","Java"],"title":"Prototype设计模式","uri":"/prototype/"},{"categories":["软件设计模式"],"content":"改写本例，用于添加另一个具体工厂和具体产品。 ","date":"2023-10-31","objectID":"/factory-method/:1:0","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"工厂方法模式结构 Figure 1-1 工厂模式方法类图\r","date":"2023-10-31","objectID":"/factory-method/:1:1","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"具体类图 Figure 1-2 类图\r","date":"2023-10-31","objectID":"/factory-method/:1:2","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"抽象工厂和抽象产品 抽象工厂：Factory 是产生Product的抽象类，具体内容由ConcreteFactory决定。Factory对于实际产生的ConcreteProduct一无所知，唯一知道的就是调用Product和产生新对象的方法。该类描述的是框架。 package framework; public abstract class Factory { public final Product create(String owner) { Product p = createProduct(owner); registerProduct(p); return p; } protected abstract Product createProduct(String owner); protected abstract void registerProduct(Product Product); } 抽象产品：规定了此Pattern所产生的对象实例应有的接口，具体内容则由子类ConcreteProduct参与者决定，该类描述的是框架。 package framework; public abstract class Product { public abstract void use(); } ","date":"2023-10-31","objectID":"/factory-method/:1:3","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"具体工厂 实际处理内容的部分，这里是一个创建账户的工厂。 package account; import java.util.Vector; import framework.*; public class AccountFactory extends Factory{ private Vector\u003cString\u003e names = new Vector\u003cString\u003e(); @Override protected Product createProduct(String name) { return new Account(name); } @Override protected void registerProduct(Product product) { names.add(((Account)product).getName()); } public Vector\u003cString\u003e getNames() { return names; } } ","date":"2023-10-31","objectID":"/factory-method/:1:4","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"具体产品 实际处理内容的部分，定义了工厂创建的账户。 package account; import framework.*; public class Account extends Product { private String name; Account(String name){ System.out.println(\"创建\" + name + \"的账户。\"); this.name = name; } public void use() { System.out.println(\"登录\" + name + \"的账户。\"); } public String getName(){ return name; } } ","date":"2023-10-31","objectID":"/factory-method/:1:5","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"结果显示 测试代码 import account.AccountFactory; import framework.*; public class Main { public static void main(String[] args) { Factory factory = new AccountFactory(); Product p1 = factory.create(\"张三\"); Product p2 = factory.create(\"李四\"); Product p3 = factory.create(\"王五\"); p1.use(); p2.use(); p3.use(); } } 测试结果 Figure 1-3\r","date":"2023-10-31","objectID":"/factory-method/:1:6","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"请举例说明其他的工厂模式的应用。 ","date":"2023-10-31","objectID":"/factory-method/:2:0","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"简单工厂模式 简单工厂模式结构 Figure 2-1 简单工厂类图\r其中根据上图可知，简单工厂模式包含以下3个角色: Factory（工厂角色）：即工厂类，它是简单工厂模式的核心，负责实现创建所有产品实例的内部逻辑；其可以被外界直接调用，创建所需的产品对象。 AbstractProduct（抽象产品角色）：它是工厂类创建的所有对象的父类，封装了各种产品对象的共有方法。 Product（具体产品角色）：它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。 简单工厂模式实现 三种角色的典型代码如下： Factory public class Factory { // 静态工厂方法 public static AbstractProduct createProduct(String arg) { AbstractProduct product = null; if (arg.equalsIgnoreCase(\"1\")) { product = new Product1(); } else if (arg.equalsIgnoreCase(\"2\")) { product = new Product2(); } return product; } } AbstractProduct public abstract class AbstractProduct { // 所有产品类的公共业务方法 public void methodSame() { // 公有方法的实现 } // 声明抽象业务方法 public abstract void methodDiff() { } } Product public class Product1 extends AbstractProduct { // 实现业务方法 public void methodDiff() { // 业务方法的实现 } } 简单工厂模式应用 Figure 2-2 简单工厂应用\r具体产品Circle、Rectangle、Triangle public class Circle extends Shape { @Override public void draw() { System.out.println(\"绘制圆形\"); } @Override public void erase() { System.out.println(\"擦除圆形\"); } } public class Rectangle extends Shape { @Override public void draw() { System.out.println(\"绘制长方形\"); } @Override public void erase() { System.out.println(\"擦除长方形\"); } } public class Triangle extends Shape { @Override public void draw() { System.out.println(\"绘制三角形\"); } @Override public void erase() { System.out.println(\"擦除三角形\"); } } 抽象产品Shape public abstract class Shape { /** * 绘制图形 */ public abstract void draw(); /** * 擦除图形 */ public abstract void erase(); } 简单工厂ShapeFactory public class ShapeFactory { public static Shape createShape(String type){ Shape shape = null; if (type.equalsIgnoreCase(\"Circle\")) { shape = new Circle(); } else if (type.equalsIgnoreCase(\"Rectangle\")) { shape = new Rectangle(); } else if (type.equalsIgnoreCase(\"Triangle\")) { shape = new Triangle(); } return shape; } } ","date":"2023-10-31","objectID":"/factory-method/:2:1","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"抽象工厂模式 抽象工厂模式结构 Figure 2-3 抽象工厂模式类图\r由上图可知，抽象工厂模式包含以下四个角色： AbstractProduct（抽象产品）：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法。 Product1（具体产品）：它定义具体工厂生产的具体产品的具体产品对象，实现抽象产品接口中声明的业务方法。 AbstractFactory（抽象工厂）：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。 ConcreteFactory1（具体工厂）：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。 抽象工厂模式实现 抽象工厂的典型代码如下： AbstractFactory public interface AbstractFactory { public AbstractProduct1 createProduct1(); // 工厂方法一 public AbstractProduct2 createProduct2(); // 工厂方法二 } ConcreteFactory1 public class ConcreteFactory1 implements AbstractFactory { // 工厂方法一 public AbstractProduct1 createProduct1() { return new Product1(); } // 工厂方法二 public AbstractProduct2 createProduct2() { return new Product2(); } } 抽象工厂模式应用 Figure 2-4 抽象工厂应用\r其中，接口AbstractFactory充当抽象工厂，其子类WindowsFactory、UnixFactory和LinuxFactory充当具体工厂；Text和Button充当抽象产品，其子类WindowsText、UnixText、LinuxText和WindowsButton、UnixButton、LinuxButton充当具体产品。 ","date":"2023-10-31","objectID":"/factory-method/:2:2","tags":["设计模式","Java"],"title":"Factory Method设计模式","uri":"/factory-method/"},{"categories":["软件设计模式"],"content":"针对Iterator的例子，将存储Book用的数组换成其他Collection并运行。 将数组存储方式换成ArrayList存储。 ","date":"2023-10-31","objectID":"/iterator/:1:0","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"类图 img\r","date":"2023-10-31","objectID":"/iterator/:1:1","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"Aggregate接口 聚合定义创建相应迭代器对象的接口 public interface Aggregate{ public abstract Iterator iterator(); } ","date":"2023-10-31","objectID":"/iterator/:1:2","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"Iterator接口 迭代器定义访问和遍历元素的接口 public interface Iterator { public abstract boolean hasNext(); public abstract Object next(); } ","date":"2023-10-31","objectID":"/iterator/:1:3","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"Book类 定义元素 public class Book { private String name; public Book(String name){ this.name = name; } public String getName(){ return name; } } ","date":"2023-10-31","objectID":"/iterator/:1:4","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"BookShelf类 具体聚合实现创建相应迭代器的接口，该操作返回BookShelfIterator的一个适当的实例，这里将存储Book的Collection换成了ArrayList。 import java.util.ArrayList; import java.util.List; public class BookShelf implements Aggregate{ private List\u003cBook\u003e books; public BookShelf(Integer maxSize){ books = new ArrayList\u003cBook\u003e(maxSize); } public Book getBookAt(Integer idx){ return books.get(idx); } public void appendBook(Book book){ books.add(book); } public Integer getLength(){ return books.size(); } @Override public Iterator iterator() { return new BookShelfIterator(this); } } ","date":"2023-10-31","objectID":"/iterator/:1:5","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"BookShelfIterator 类 具体迭代器实现迭代器接口 对该聚合遍历时跟踪当前位置 public class BookShelfIterator implements Iterator{ private BookShelf bookShelf; private Integer index; public BookShelfIterator(BookShelf bookShelf){ this.bookShelf = bookShelf; this.index = 0; } @Override public boolean hasNext() { if(index \u003e= bookShelf.getLength()) return false; else return true; } @Override public Object next() { Book book = bookShelf.getBookAt(index ++); return book; } } ","date":"2023-10-31","objectID":"/iterator/:1:6","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"Main类 public class Main { public static void main(String[] args) { BookShelf bookShelf = new BookShelf(4); bookShelf.appendBook(new Book(\"Around the World in 80 Days\")); bookShelf.appendBook(new Book(\"Bible\")); bookShelf.appendBook(new Book(\"Forrest Gump\")); bookShelf.appendBook(new Book(\"Triumph\")); Iterator it = bookShelf.iterator(); while(it.hasNext()){ Book book = (Book) it.next(); System.out.println(book.getName()); } } } ","date":"2023-10-31","objectID":"/iterator/:1:7","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"运行结果 运行Main类测试代码后，结果如下： Figure 1-1\r","date":"2023-10-31","objectID":"/iterator/:1:8","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"针对Iterator的例子，设计一个Specified的Iterator并运行。 ","date":"2023-10-31","objectID":"/iterator/:2:0","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"设计实现 设计实现一个由后向前遍历和获取指定下标的Iterator，重写Iterator接口中的方法，并实现该接口： ReverseIterator接口： public interface ReverseIterator { //检查有无前一个元素 public abstract boolean hasPre(); //返回聚合当中的一个元素 public abstract Object getPre(); //返回聚合中的特定元素 public abstract Object getByIndex(int index); } BookShelfReverseIterator实现类： public class BookShelfReverseIterator implements ReverseIterator { private BookShelf bookShelf; private int index; public BookShelfReverseIterator(BookShelf bookShelf) { this.bookShelf = bookShelf; this.index = bookShelf.getLength() - 1; } public boolean hasPre() { if(index \u003e= 0) { return true; } return false; } public Object getPre() { Book book = bookShelf.getBookAt(index); index--; return book; } public Object getByIndex(int index) { if(index \u003e= 0 \u0026\u0026 index \u003c bookShelf.getLength()) { Book book = bookShelf.getBookAt(index); return book; } return null; } } 测试代码如下所示： public class ReverseMain { public static void main(String[] args) { BookShelf bookShelf = new BookShelf(4); bookShelf.appendBook(new Book(\"Around the World in 80 Days\")); bookShelf.appendBook(new Book(\"Bible\")); bookShelf.appendBook(new Book(\"Forrest Gump\")); bookShelf.appendBook(new Book(\"Triumph\")); ReverseIterator rit = bookShelf.rIterator(); System.out.println(\"由后向前遍历\"); while(rit.hasPre()){ Book book = (Book) rit.getPre(); System.out.println(book.getName()); } System.out.println(\"获取指定元素\"); Book book = (Book) rit.getByIndex(2); System.out.println(book.getName()); } } ","date":"2023-10-31","objectID":"/iterator/:2:1","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"运行结果 Figure 2-1\r","date":"2023-10-31","objectID":"/iterator/:2:2","tags":["设计模式","Java"],"title":"Iterator设计模式","uri":"/iterator/"},{"categories":["软件设计模式"],"content":"什么是双向适配器？ 在对象适配器使用过程中，如果在适配器中同时包含对目标类和适配者类的引用，适配者可以通过它调用目标类的方法，目标类也可以通过它调用适配者类的方法，那么该适配器就是一个双向适配器；即双向适配器类可以把适配者接口转换成目标接口，也可以把目标接口转换成适配者接口。 比如，单向适配器只能把交流220V的电压转换为直流12V的电压，而双向适配器可以互相转换，即也可以把直流12V的电压转换为交流220V的电压。 ","date":"2023-10-31","objectID":"/adaptor/:1:0","tags":["设计模式","Java"],"title":"Adaptor设计模式","uri":"/adaptor/"},{"categories":["软件设计模式"],"content":"举例说明实现方式 交流220V电压和直流12V电压的相互转换： 交流220V：接口+实现类 直流12V：接口+实现类 转换器：适配器类 交流220V接口和实现类： Figure 2-1\rFigure 2-2\r直流12V接口和实现类： Figure 2-3\rFigure 2-4\r转换器的实现： Figure 2-5\r测试： Figure 2-6\r测试结果： Figure 2-7\r","date":"2023-10-31","objectID":"/adaptor/:2:0","tags":["设计模式","Java"],"title":"Adaptor设计模式","uri":"/adaptor/"},{"categories":["动手学深度学习"],"content":"从全连接层到卷积 卷积神经网络（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:0","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"不变性 卷积神经网络正是将空间不变性（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。适合于计算机视觉的神经网络架构的特点： 平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。 局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:1","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"多层感知机的限制 若用多层感知机处理图像信息，首先，多层感知机的输入是二维图像$\\mathbf{X}$，其隐藏表示$\\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。其中$\\mathbf{X}$和$\\mathbf{H}$具有相同的形状。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。使用$[\\mathbf{X}]_ {i, j}$和$[\\mathbf{H}]_ {i, j}$分别表示输入图像和隐藏表示中位置（$i$,$j$）处的像素。为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量$\\mathsf{W}$。假设$\\mathbf{U}$包含偏置参数，可以将全连接层形式化地表示为： $$ \\begin{aligned} \\left[\\mathbf{H}\\right]_ {i, j} \u0026= [\\mathbf{U}]_ {i, j} + \\sum_k \\sum_l[\\mathsf{W}]_ {i, j, k, l} [\\mathbf{X}]_ {k, l}\\\\ \u0026= [\\mathbf{U}]_ {i, j} + \\sum_ a \\sum_ b [\\mathsf{V}]_ {i, j, a, b} [\\mathbf{X}]_ {i+a, j+b} \\end{aligned} $$ 其中，从$\\mathsf{W}$到$\\mathsf{V}$的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。我们只需重新索引下标$(k, l)$，使$k = i+a$、$l = j+b$，由此可得$[\\mathsf{V}]_ {i, j, a, b} = [\\mathsf{W}]_ {i, j, i+a, j+b}$。索引$a$和$b$通过在正偏移和负偏移之间移动覆盖了整个图像。对于隐藏表示中任意给定位置（$i$,$j$）处的像素值$[\\mathbf{H}]_ {i, j}$，可以通过在$x$中以$(i, j)$为中心对像素进行加权求和得到，加权使用的权重为$[\\mathsf{V}]_{i, j, a, b}$。 平移不变性 现在引用上述的第一个原则：平移不变性。这意味着检测对象在输入$\\mathbf{X}$中的平移，应该仅导致隐藏表示$\\mathbf{H}$中的平移。也就是说，$\\mathsf{V}$和$\\mathbf{U}$实际上不依赖于$(i, j)$的值，即$[\\mathsf{V}]_ {i, j, a, b} = [\\mathbf{V}]_ {a, b}$。并且$\\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\\mathbf{H}$定义为： $$ [\\mathbf{H}]_ {i, j} = u + \\sum_ a\\sum_ b [\\mathbf{V}]_ {a, b} [\\mathbf{X}]_ {i+a, j+b} $$ 这就是卷积（convolution）。我们是在使用系数$[\\mathbf{V}]_ {a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\\mathbf{H}]_ {i, j}$。注意，$[\\mathbf{V}]_ {a, b}$的系数比$[\\mathsf{V}]_ {i, j, a, b}$少很多，因为前者不再依赖于图像中的位置。 局部性 现在引用上述的第二个原则：局部性。如上所述，为了收集用来训练参数$[\\mathbf{H}]_ {i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方。这意味着在$|a|\u003e \\Delta$或$|b| \u003e \\Delta$的范围之外，我们可以设置$[\\mathbf{V}]_ {a, b} = 0$。因此可以将$[\\mathbf{H}]_ {i, j}$重写为 $$ [\\mathbf{H}]_ {i, j} = u + \\sum_ {a = -\\Delta}^{\\Delta} \\sum_ {b = -\\Delta}^{\\Delta} [\\mathbf{V}]_ {a, b} [\\mathbf{X}]_ {i+a, j+b} $$ 简而言之，上述公式是一个卷积层（convolutional layer），而卷积神经网络是包含卷积层的一类特殊的神经网络。在深度学习研究社区中，$\\mathbf{V}$被称为卷积核（convolution kernel）或者滤波器（filter），亦或简单地称之为该卷积层的权重，通常该权重是可学习的参数。当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:2","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"卷积 在进一步讨论之前，我们先简要回顾一下为什么上面的操作被称为卷积。在数学中，两个函数（比如$f, g: \\mathbb{R}^d \\to \\mathbb{R}$）之间的“卷积”被定义为 $$ (f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z} $$ 也就是说，卷积是当把一个函数“翻转”并移位$\\mathbf{x}$时，测量$f$和$g$之间的重叠。当为离散对象时，积分就变成求和。例如，对于从定义域为$\\mathbb{Z}$的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义： $$ (f * g)(i) = \\sum_a f(a) g(i-a) $$ 对于二维张量，则为函数$f$的自变量$(a, b)$和函数$g$的自变量$(i-a, j-b)$上的对应加和： $$ (f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b) $$ 这看起来类似于公式3，但有一个主要区别：这里不是使用$(i+a, j+b)$，而是使用差值。然而，这种区别是表面的，因为我们总是可以匹配公式3和公式6之间的符号。我们在公式3中的原始定义更正确地描述了互相关（cross-correlation）。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:3","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"通道 然而这种方法有一个问题：我们忽略了图像一般包含三个通道/三种原色（红色、绿色和蓝色）。实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含$1024 \\times 1024 \\times 3$个像素。前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示。因此，我们将$\\mathsf{X}$索引为$[\\mathsf{X}]_ {i, j, k}$。由此卷积相应地调整为$[\\mathsf{V}]_ {a,b,c}$，而不是$[\\mathbf{V}]_ {a,b}$。 此外，由于输入图像是三维的，我们的隐藏表示$\\mathsf{H}$也最好采用三维张量。换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。因此，我们可以把隐藏表示想象为一系列具有二维张量的通道（channel）。这些通道有时也被称为特征映射（feature maps），因为每个通道都向后续层提供一组空间化的学习特征。直观上可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。 为了支持输入$\\mathsf{X}$和隐藏表示$\\mathsf{H}$中的多个通道，我们可以在$\\mathsf{V}$中添加第四个坐标，即$[\\mathsf{V}]_ {a, b, c, d}$。综上所述， $$ [\\mathsf{H}]_ {i,j,d} = u + \\sum_ {a = -\\Delta}^{\\Delta} \\sum_ {b = -\\Delta}^{\\Delta} \\sum_ c [\\mathsf{V}]_ {a, b, c, d} [\\mathsf{X}]_ {i+a, j+b, c} $$ 其中隐藏表示$\\mathsf{H}$中的索引$d$表示输出通道，而随后的输出将继续以三维张量$\\mathsf{H}$作为输入进入下一个卷积层。所以，上述公式可以定义具有多个通道的卷积层，而其中$\\mathsf{V}$是该卷积层的权重。 然而，仍有许多问题亟待解决。例如，图像中是否到处都有存在目标物体的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:4","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"图像卷积 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:0","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"互相关运算 严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是互相关运算（cross-correlation），而不是卷积运算。根据上一节中的描述，在卷积层中，输入张量和核张量通过互相关运算产生输出张量。 首先，暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在下图中，输入是高度为$3$、宽度为$3$的二维张量（即形状为$3 \\times 3$）。卷积核的高度和宽度都是$2$，而卷积核窗口（或卷积窗口）的形状由内核的高度和宽度决定（即$2 \\times 2$），Input中的蓝色框表示卷积窗口。 Figure 2-1 二维互相关运算\r在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此得出了这一位置的输出张量值。在如上例子中，输出张量的四个元素由二维互相关运算得到，这个输出高度为$2$、宽度为$2$，如下所示： $$ 0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\ 1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\ 3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\ 4\\times0+5\\times1+7\\times2+8\\times3=43. $$ 注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，而卷积核只与图像中每个大小完全适合的位置进行互相关运算。所以，输出大小等于输入大小$n_h \\times n_w$减去卷积核大小$k_h \\times k_w$，即：$(n_h-k_h+1) \\times (n_w-k_w+1)$ 这是因为我们需要足够的空间在图像上“移动”卷积核。稍后，我们将看到如何通过在图像边界周围填充零来保证有足够的空间移动卷积核，从而保持输出大小不变。接下来，我们在corr2d函数中实现如上过程，该函数接受输入张量X和卷积核张量K，并返回输出张量Y。 import torch from torch import nn from d2l import torch as d2l def corr2d(X, K): \"\"\"计算二维互相关运算\"\"\" h, w = K.shape # 卷积核的高和宽 Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i:i + h, j:j + w] * K).sum() return Y X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) output: tensor([[19., 25.], [37., 43.]]) ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:1","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"卷积层 卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。就像之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重。 基于上面定义的corr2d函数实现二维卷积层。在__init__构造函数中，将weight和bias声明为两个模型参数。前向传播函数调用corr2d函数并添加偏置。 class Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight = nn.Parameter(torch.rand(kernel_size)) self.bias = nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias 高度和宽度分别为$h$和$w$的卷积核可以被称为$h \\times w$卷积或$h \\times w$卷积核，同样也将带有$h \\times w$卷积核的卷积层称为$h \\times w$卷积层。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:2","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"图像中目标的边缘监测 下面时卷积层的一个简单应用：通过找到像素变化的位置，来检测图像中不同颜色的边缘。首先，我们一个$6\\times 8$像素的黑白图像，中间四列为黑色（$0$），其余像素为白色（$1$）。 X = torch.ones((6, 8)) X[:, 2:6] = 0 X output: tensor([[1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.]]) 接下来，构造一个高度为$1$、宽度为$2$的卷积核K。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。 K = torch.tensor([[1.0, -1.0]]) 现在，对参数X（输入）和K（卷积核）执行互相关运算。如下所示，输出Y中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘，其他情况的输出为$0$。 Y = corr2d(X, K) Y output: tensor([[ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.]]) 现在将输入的二维图像转置，再进行如上的互相关运算。其输出如下，之前检测到的垂直边缘消失了。不出所料，这个卷积核K只可以检测垂直边缘，无法检测水平边缘。 corr2d(X.t(), K) output: tensor([[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]) ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:3","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"卷积核 如果我们只需寻找黑白边缘，那么以上[1, -1]的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计滤波器。那么就需要学习由X生成Y的卷积核。 下面将检查是否可以通过仅查看*“输入-输出”对*来学习由X生成Y的卷积核。首先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较Y与卷积层输出的平方误差，然后计算梯度来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。 # 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核 conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False) # 前两个参数为输入通道数和输出通道数 # 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度）， # 其中批量大小和通道数都为1 X = X.reshape((1, 1, 6, 8)) Y = Y.reshape((1, 1, 6, 7)) lr = 3e-2 # 学习率 for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.zero_grad() l.sum().backward() # 迭代卷积核 conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f'epoch {i+1}, loss {l.sum():.3f}') output: epoch 2, loss 7.253 epoch 4, loss 1.225 epoch 6, loss 0.209 epoch 8, loss 0.036 epoch 10, loss 0.007 在$10$次迭代之后，误差已经降到足够低，下面来看看我们所学的卷积核的权重张量。 conv2d.weight.data.reshape((1, 2)) output: tensor([[ 0.9829, -0.9892]]) 可以发现上面学习到的卷积核权重非常接近我们之前定义的卷积核K。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:4","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"互相关和卷积 回想一下我们在上一节中观察到的互相关和卷积运算之间的对应关系。为了得到正式的卷积运算输出，我们需要执行上一节中严格定义的卷积运算，而不是互相关运算。幸运的是，它们差别不大，我们只需水平和垂直翻转二维卷积核张量，然后对输入张量执行互相关运算。 值得注意的是，由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷积层的输出都不会受到影响。为了说明这一点，假设卷积层执行互相关运算并学习Figure 2-1中的卷积核，该卷积核在这里由矩阵$\\mathbf{K}$表示。假设其他条件不变，当这个层执行严格的卷积时，学习的卷积核$\\mathbf{K}’$在水平和垂直翻转之后将与$\\mathbf{K}$相同。也就是说，当卷积层对Figure 2-1中的输入和$\\mathbf{K}’$执行严格卷积运算时，将得到与互相关运算中Figure 2-1相同的输出。 为了与深度学习文献中的标准术语保持一致，我们将继续把“互相关运算”称为卷积运算，尽管严格地说，它们略有不同。此外，对于卷积核张量上的权重，我们称其为元素。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:5","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"特征映射和感受野 如在上一节中所述，Figure 2-1中输出的卷积层有时被称为特征映射（feature map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。在卷积神经网络中，对于某一层的任意元素$x$，其感受野（receptive field）是指在前向传播期间可能影响$x$计算的所有元素（来自所有先前层）。 请注意，感受野可能大于输入的实际大小。用Figure 2-1为例来解释感受野：给定$2 \\times 2$卷积核，阴影输出元素值$19$的感受野是输入阴影部分的四个元素。假设之前输出为$\\mathbf{Y}$，其大小为$2 \\times 2$，现在我们在其后附加一个卷积层，该卷积层以$\\mathbf{Y}$为输入，输出单个元素$z$。在这种情况下，$\\mathbf{Y}$上的$z$的感受野包括$\\mathbf{Y}$的所有四个元素，而输入的感受野包括最初所有九个输入元素。因此，当一个特征图中的任意元素需要检测更广区域的输入特征时，我们可以构建一个更深的网络。 ","date":"2023-10-30","objectID":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:6","tags":["d2l","pytorch"],"title":"6 卷积神经网络","uri":"/6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"层和块 事实证明，研究讨论“比单个层大”但“比整个模型小”的组件更有价值，由此引入了神经网络块的概念。块（block）可以描述单个层、由多个层组成的组件或整个模型本身。使用块进行抽象的一个好处是可以将一些块组合成更大的组件，这一过程通常是递归的，如下图所示。 通过定义代码来按需生成任意复杂度的块，可以通过简洁的代码实现复杂的神经网络。 从编程的角度来看，块由类（class）表示。它的任何子类都必须定义一个将其输入转换为输出的前向传播函数，并且必须存储任何必需的参数（但有些块不需要任何参数）。最后，为了计算梯度，块必须具有反向传播函数。在定义我们自己的块时，由于自动微分提供了一些后端实现，我们只需要考虑前向传播函数和必需的参数。 下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接隐藏层，然后是一个具有10个隐藏单元且不带激活函数的全连接输出层。 import torch from torch import nn from torch.nn import functional as F net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) X = torch.rand(2, 20) net(X) output: tensor([[ 0.2172, 0.2640, 0.1634, 0.1557, 0.0725, 0.0620, 0.0563, -0.1232, -0.0499, 0.0680], [ 0.3428, 0.1960, 0.1856, 0.0338, -0.0193, 0.0314, -0.0053, -0.0298, 0.0883, 0.0390]], grad_fn=\u003cAddmmBackward0\u003e) 上述例子通过实例化nn.Sequential来构建模型，层的执行顺序是作为参数传递的。简而言之，(nn.Sequential定义了一种特殊的Module)，即在PyTorch中表示一个块的类，它维护了一个由Module组成的有序列表。注意，两个全连接层都是Linear类的实例，Linear类本身就是Module的子类。另外，到目前为止，我们一直在通过net(X)调用我们的模型来获得模型的输出。这实际上是net.__call__(X)的简写。这个前向传播函数非常简单：它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:1:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"自定义块 在自定义一个块之前，需要总结每一个块必须提供的基本功能： 将输入数据作为其前向传播函数的参数 通过前向传播函数来生成输出 计算其输出关于输入的梯度，可通过其反向传播函数进行访问 存储和访问前向传播计算所需的参数 根据需要初始化模型参数 下面的MLP类继承了表示块的类。我们的实现只需要提供构造函数（Python中的__init__函数）和前向传播函数。 class MLP(nn.Module): # 用模型参数声明层。这里，我们声明两个全连接的层 def __init__(self): # 调用MLP的父类Module的构造函数来执行必要的初始化。 # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍） super().__init__() self.hidden = nn.Linear(20, 256) # 隐藏层 self.out = nn.Linear(256, 10) # 输出层 # 定义模型的前向传播，即如何根据输入X返回所需的模型输出 def forward(self, X): # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。 return self.out(F.relu(self.hidden(X))) 上述代码的前向传播函数，以X作为输入，计算带有激活函数的隐藏表示，并输出其未规范化的输出值。在这个MLP实现中，两个层都是实例变量。接着实例化多层感知机的层，然后在每次调用前向传播函数时调用这些层。首先，__init__函数通过super().__init__()调用父类的__init__函数，然后实例化两个全连接层，分别为self.hidden和self.out。注意，我们不必担心反向传播函数或参数初始化，系统将自动生成这些。 net = MLP() net(X) output: tensor([[-0.1039, -0.1376, 0.0847, 0.1495, 0.0881, -0.1072, -0.5245, 0.1337, 0.1617, 0.1733], [-0.0435, -0.0553, -0.0714, 0.2861, 0.2305, -0.2955, -0.4526, 0.1166, 0.1557, 0.1899]], grad_fn=\u003cAddmmBackward0\u003e) 块的一个主要优点是它的多功能性。我们可以子类化块以创建层（如全连接层的类）、整个模型（如上面的MLP类）或具有中等复杂度的各种组件。比如在处理卷积神经网络时，充分利用了这种多功能性。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:1:1","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"顺序块 Sequential的设计是为了把其他模块串起来。为了构建我们自己的简化的MySequential， 我们只需要定义两个关键函数： 一种将块逐个追加到列表中的函数； 一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。 下面的MySequential类提供了与默认Sequential类相同的功能。 class MySequential(nn.Module): def __init__(self, *args): super().__init__() for idx, module in enumerate(args): # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员 # 变量_modules中。_module的类型是OrderedDict self._modules[str(idx)] = module def forward(self, X): # OrderedDict保证了按照成员添加的顺序遍历它们 for block in self._modules.values(): X = block(X) return X __init__函数将每个模块逐个添加到有序字典_modules中。简而言之，_modules的主要优点是：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。 当MySequential的前向传播函数被调用时， 每个添加的块都按照它们被添加的顺序执行。 现在可以使用MySequential类重新实现多层感知机。 net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) net(X) output: tensor([[-0.2120, 0.1035, 0.1243, -0.1841, 0.1651, 0.0483, -0.0668, -0.0528, -0.1805, -0.0286], [-0.2596, 0.2426, 0.1686, -0.3241, -0.0032, 0.1208, -0.0288, -0.1468, -0.1011, 0.0968]], grad_fn=\u003cAddmmBackward0\u003e) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:1:2","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"在前向传播函数中执行代码 Sequential类使模型构造变得简单，允许我们组合新的架构，而不必定义自己的类。然而，并不是所有的架构都是简单的顺序架构。当需要更强的灵活性时，我们需要定义自己的块。例如，我们可能希望在前向传播函数中执行Python的控制流。此外，我们可能希望执行任意的数学运算，而不是简单地依赖预定义的神经网络层。 到目前为止，我们网络中的所有操作都对网络的激活值及网络的参数起作用。然而，有时我们可能希望合并既不是上一层的结果也不是可更新参数的项，我们称之为常数参数（constant parameter）。例如，我们需要一个计算函数$f(\\mathbf{x},\\mathbf{w}) = c \\cdot \\mathbf{w}^\\top \\mathbf{x}$的层，其中$\\mathbf{x}$是输入，$\\mathbf{w}$是参数，$c$是某个在优化过程中没有更新的指定常量。因此实现了一个FixedHiddenMLP类，如下所示： class FixedHiddenMLP(nn.Module): def __init__(self): super().__init__() # 不计算梯度的随机权重参数。因此其在训练期间保持不变 self.rand_weight = torch.rand((20, 20), requires_grad=False) self.linear = nn.Linear(20, 20) def forward(self, X): X = self.linear(X) # 使用创建的常量参数以及relu和mm函数 X = F.relu(torch.mm(X, self.rand_weight) + 1) # 复用全连接层。这相当于两个全连接层共享参数 X = self.linear(X) # 控制流 while X.abs().sum() \u003e 1: X /= 2 return X.sum() 在这个FixedHiddenMLP模型中，我们实现了一个隐藏层，其权重（self.rand_weight）在实例化时被随机初始化，之后为常量。这个权重不是一个模型参数，因此它永远不会被反向传播更新。然后，神经网络将这个固定层的输出通过一个全连接层。 注意，在返回输出之前，模型做了一些不寻常的事情：它运行了一个while循环，在$L_1$范数大于$1$的条件下，将输出向量除以$2$，直到它满足条件为止。最后，模型返回了X中所有项的和。此操作可能不会常用于在任何实际任务中，我们只展示如何将任意代码集成到神经网络计算的流程中。 net = FixedHiddenMLP() net(X) output: tensor(-0.0914, grad_fn=\u003cSumBackward0\u003e) 我们可以混合搭配各种组合块的方法。在下面的例子中，我们以一些方法嵌套块： class NestMLP(nn.Module): def __init__(self): super().__init__() self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU()) self.linear = nn.Linear(32, 16) def forward(self, X): return self.linear(self.net(X)) chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP()) chimera(X) output: tensor(0.0713, grad_fn=\u003cSumBackward0\u003e) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:1:3","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"参数管理 在选择了架构并设置了超参数后，就进入了训练阶段。此时，我们的目标是找到使损失函数最小化的模型参数值。经过训练后，我们将需要使用这些参数来做出未来的预测。此外，有时我们希望提取参数，以便在其他环境中复用它们，将模型保存下来，以便它可以在其他软件中执行，或者为了获得科学的理解而进行检查。 首先定义一个具有单隐藏层的多层感知机： import torch from torch import nn net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1)) X = torch.rand(size=(2, 4)) net(X) output: tensor([[-0.0598], [ 0.1842]], grad_fn=\u003cAddmmBackward0\u003e) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:2:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"参数访问 我们从已有模型中访问参数。当通过Sequential类定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是一个列表一样，每层的参数都在其属性中。如下所示，检查第二个全连接层的参数： print(net[2].state_dict()) output: OrderedDict([('weight', tensor([[ 0.0051, -0.3365, 0.2276, -0.1116, 0.0760, -0.3333, 0.2590, 0.1495]])), ('bias', tensor([-0.0554]))]) 从输出的结果可以知道：首先，这个全连接层包含两个参数，分别是该层的权重和偏置。两者都存储为单精度浮点数（float32）。注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。 每个参数都表示为参数类的一个实例。要对参数执行任何操作，需要先访问底层的数值。下面的代码从第二个全连接层（即第三个神经网络层）提取偏置，提取后返回的是一个参数类实例，并进一步访问该参数的值。 print(type(net[2].bias)) print(net[2].bias) print(net[2].bias.data) output: \u003cclass 'torch.nn.parameter.Parameter'\u003e Parameter containing: tensor([-0.0554], requires_grad=True) tensor([-0.0554]) 参数是复合的对象，包含值、梯度和额外信息。这就是我们需要显式参数值的原因。除了值之外，我们还可以访问每个参数的梯度。在上面这个网络中，由于我们还没有调用反向传播，所以参数的梯度处于初始状态。 net[2].weight.grad == None output: True 当我们需要对所有参数执行操作时，逐个访问它们可能会很麻烦。当我们处理更复杂的块（例如，嵌套块）时，情况可能会变得特别复杂， 因为我们需要递归整个树来提取每个子块的参数。下面将通过演示来比较访问第一个全连接层的参数和访问所有层。 print(*[(name, param.shape) for name, param in net[0].named_parameters()]) print(*[(name, param.shape) for name, param in net.named_parameters()]) output: ('weight', torch.Size([8, 4])) ('bias', torch.Size([8])) ('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1])) 如果我们将多个块相互嵌套，下面将研究参数命名约定是如何工作的。我们首先定义一个生成块的函数（可以说是“块工厂”），然后将这些块组合到更大的块中。 def block1(): return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU()) def block2(): net = nn.Sequential() for i in range(4): # 在这里嵌套 net.add_module(f'block {i}', block1()) return net rgnet = nn.Sequential(block2(), nn.Linear(4, 1)) X = torch.rand(size=(2, 4)) rgnet(X) output: tensor([[0.2746], [0.2747]], grad_fn=\u003cAddmmBackward0\u003e) 设计了网络后，可以看到它是如何工作的： print(rgnet) output: Sequential( (0): Sequential( (block 0): Sequential( (0): Linear(in_features=4, out_features=8, bias=True) (1): ReLU() (2): Linear(in_features=8, out_features=4, bias=True) (3): ReLU() ) (block 1): Sequential( (0): Linear(in_features=4, out_features=8, bias=True) (1): ReLU() (2): Linear(in_features=8, out_features=4, bias=True) (3): ReLU() ) (block 2): Sequential( (0): Linear(in_features=4, out_features=8, bias=True) (1): ReLU() (2): Linear(in_features=8, out_features=4, bias=True) (3): ReLU() ) (block 3): Sequential( (0): Linear(in_features=4, out_features=8, bias=True) (1): ReLU() (2): Linear(in_features=8, out_features=4, bias=True) (3): ReLU() ) ) (1): Linear(in_features=4, out_features=1, bias=True) ) 因为层是分层嵌套的，所以可以像通过嵌套列表索引一样访问它们。下面，我们访问第一个主要的块中、第二个子块的第一层的偏置项。 rgnet[0][1][0].bias.data output: tensor([-0.0221, -0.2074, -0.1290, 0.3668, -0.1693, -0.3298, -0.2983, 0.0146]) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:2:1","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"参数初始化 默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵，这个范围是根据输入和输出维度计算出的。PyTorch的nn.init模块提供了多种预置初始化方法。 内置初始化 首先调用内置的初始化器。下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量，且将偏置参数设置为0。 def init_normal(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.zeros_(m.bias) net.apply(init_normal) net[0].weight.data[0], net[0].bias.data[0] output: (tensor([ 0.0081, -0.0059, 0.0007, -0.0083]), tensor(0.)) 我们还可以将所有参数初始化为给定的常数，比如初始化为1。 def init_constant(m): if type(m) == nn.Linear: nn.init.constant_(m.weight, 1) nn.init.zeros_(m.bias) net.apply(init_constant) net[0].weight.data[0], net[0].bias.data[0] output: (tensor([1., 1., 1., 1.]), tensor(0.)) 我们还可以对某些块应用不同的初始化方法。例如，下面我们使用Xavier初始化方法初始化第一个神经网络层，然后将第三个神经网络层初始化为常量值42。 def init_xavier(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight) def init_42(m): if type(m) == nn.Linear: nn.init.constant_(m.weight, 42) net[0].apply(init_xavier) net[2].apply(init_42) print(net[0].weight.data[0]) print(net[2].weight.data) output: tensor([ 0.0999, -0.5481, 0.3967, 0.0342]) tensor([[42., 42., 42., 42., 42., 42., 42., 42.]]) 自定义初始化 有时，深度学习框架没有提供我们需要的初始化方法。在下面的例子中，我们使用以下的分布为任意权重参数$w$定义初始化方法： $$ \\begin{aligned} w \\sim \\begin{cases} U(5, 10) \u0026 \\text{ 可能性 } \\frac{1}{4} \\\\ 0 \u0026 \\text{ 可能性 } \\frac{1}{2} \\\\ U(-10, -5) \u0026 \\text{ 可能性 } \\frac{1}{4} \\end{cases} \\end{aligned} $$ 同样，下面实现了一个my_init函数来应用到net。 def my_init(m): if type(m) == nn.Linear: print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0]) nn.init.uniform_(m.weight, -10, 10) m.weight.data *= m.weight.data.abs() \u003e= 5 net.apply(my_init) net[0].weight[:2] output: Init weight torch.Size([8, 4]) Init weight torch.Size([1, 8]) tensor([[0.0000, 7.1143, -0.0000, -0.0000], [0.0000, 0.0000, 9.2134, 7.8409]], grad_fn=\u003cSliceBackward0\u003e) 我们始终可以直接设置参数： net[0].weight.data[:] += 1 net[0].weight.data[0, 0] = 42 net[0].weight.data[0] output: tensor([42.0000, 8.1143, 1.0000, 1.0000]) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:2:2","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"参数绑定 有时我们希望在多个层间共享参数：我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。 # 我们需要给共享层一个名称，以便可以引用它的参数 shared = nn.Linear(8, 8) net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1)) net(X) # 检查参数是否相同 print(net[2].weight.data[0] == net[4].weight.data[0]) net[2].weight.data[0, 0] = 100 # 确保它们实际上是同一个对象，而不只是有相同的值 print(net[2].weight.data[0] == net[4].weight.data[0]) output: tensor([True, True, True, True, True, True, True, True]) tensor([True, True, True, True, True, True, True, True]) 这个例子表明第三个和第五个神经网络层的参数是绑定的。它们不仅值相等，而且由相同的张量表示。因此，如果我们改变其中一个参数，另一个参数也会改变。这里有一个问题：当参数绑定时，梯度会发生什么情况？答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层（即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:2:3","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"自定义层 深度学习成功背后的一个因素是神经网络的灵活性：我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。在这些情况下，必须构建自定义层。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:3:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"不带参数的层 首先，构造一个没有任何参数的自定义层。下面的CenteredLayer类要从其输入中减去均值。要构建它，我们只需继承基础层类并实现前向传播功能。 import torch import torch.nn.functional as F from torch import nn class CenteredLayer(nn.Module): def __init__(self): super().__init__() def forward(self, X): return X - X.mean() 向该层提供一些数据： layer = CenteredLayer() layer(torch.FloatTensor([1, 2, 3, 4, 5])) output: tensor([-2., -1., 0., 1., 2.]) 现在，我们可以将层作为组件合并到更复杂的模型中。 net = nn.Sequential(nn.Linear(8, 128), CenteredLayer()) 作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。由于我们处理的是浮点数，因为存储精度的原因，仍然可能会看到一个非常小的非零数。 Y = net(torch.rand(4, 8)) Y.mean() output: tensor(-1.8626e-09, grad_fn=\u003cMeanBackward0\u003e) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:3:1","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"带参数的层 以上我们知道了如何定义简单的层，下面我们继续定义具有参数的层，这些参数可以通过训练进行调整。我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。比如管理访问、初始化、共享、保存和加载模型参数。这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。 现在，让我们实现自定义版本的全连接层。该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用修正线性单元（relu）作为激活函数。该层需要输入参数：in_units和units，分别表示输入数和输出数。 class MyLinear(nn.Module): def __init__(self, in_units, units): super().__init__() self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) def forward(self, X): linear = torch.matmul(X, self.weight.data) + self.bias.data return F.relu(linear) 接下来，我们实例化MyLinear类并访问其模型参数： linear = MyLinear(5, 3) linear.weight output: Parameter containing: tensor([[-1.4967, 0.4762, 0.1728], [ 3.3487, 1.5446, -1.4548], [ 0.4705, 0.0455, 0.5935], [ 0.5505, -1.8667, 0.3717], [-0.0396, -0.0339, -1.2275]], requires_grad=True) 使用自定义层直接执行前向传播计算： linear(torch.rand(2, 5)) output: tensor([[1.6577, 0.6769, 0.0000], [0.0000, 0.3016, 0.0000]]) 我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。 net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1)) net(torch.rand(2, 64)) output: tensor([[2.0534], [0.0973]]) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:3:2","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"读写文件 到目前为止，我们讨论了如何处理数据，以及如何构建、训练和测试深度学习模型。然而，有时我们希望保存训练的模型，以备将来在各种环境中使用（比如在部署中进行预测）。此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果，以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:4:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"加载和保存张量 对于单个张量，可以直接调用load和save函数分别读写它们。这两个函数都要求我们提供一个名称，save要求将要保存的变量作为输入。 import torch from torch import nn from torch.nn import functional as F x = torch.arange(4) torch.save(x, 'x-file') 现在就可以将存储在文件中的数据读回内存： x2 = torch.load('x-file') x2 output: tensor([0, 1, 2, 3]) 我们也可以存储一个张量列表，然后把它们读回内存。 y = torch.zeros(4) torch.save([x, y],'x-files') x2, y2 = torch.load('x-files') (x2, y2) output: (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.])) 我们甚至可以写入或读取从字符串映射到张量的字典，当我们要读取或写入模型中的所有权重时，这很方便 mydict = {'x': x, 'y': y} torch.save(mydict, 'mydict') mydict2 = torch.load('mydict') mydict2 output: {'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])} ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:4:1","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"加载和保存模型参数 保存单个权重向量（或其他张量）确实有用，但是如果想保存整个模型，并在以后加载它们，单独保存每个向量则会变得很麻烦。毕竟可能有数百个参数散布在各处。因此，深度学习框架提供了内置函数来保存和加载整个网络。需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。例如，如果我们有一个3层多层感知机，我们需要单独指定架构。因为模型本身可以包含任意代码，所以模型本身难以序列化。因此，为了恢复模型，我们需要用代码生成架构，然后从磁盘加载参数。先定义一个多层感知机： class MLP(nn.Module): def __init__(self): super().__init__() self.hidden = nn.Linear(20, 256) self.output = nn.Linear(256, 10) def forward(self, x): return self.output(F.relu(self.hidden(x))) net = MLP() X = torch.randn(size=(2, 20)) Y = net(X) 接下来，将模型的参数存储在一个叫做“mlp.params”的文件中： torch.save(net.state_dict(), 'mlp.params') 为了恢复模型，可以直接读取文件中存储的参数： net_clone = MLP() net_clone.load_state_dict(torch.load('mlp.params')) net_clone.eval() output: MLP( (hidden): Linear(in_features=20, out_features=256, bias=True) (output): Linear(in_features=256, out_features=10, bias=True) ) 由于两个实例具有相同的模型参数，在输入相同的X时，两个实例的计算结果应该相同。验证如下： Y_clone = net_clone(X) Y_clone == Y output: tensor([[True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, True]]) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:4:2","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"GPU 查看显卡信息 nvidia-smi ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:5:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"计算设备 我们可以指定用于存储和计算的设备，如CPU和GPU。默认情况下，张量是在内存中创建的，然后使用CPU计算它。 在PyTorch中，CPU和GPU可以用torch.device('cpu')和torch.device('cuda')表示。cpu设备意味着所有物理CPU和内存，这意味着PyTorch的计算将尝试使用所有CPU核心。然而，gpu设备只代表一个卡和相应的显存。如果有多个GPU，可以使用torch.device(f'cuda:{i}')来表示第$i$块GPU（$i$从0开始）。另外，cuda:0和cuda是等价的。 import torch from torch import nn torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1') output: (device(type='cpu'), device(type='cuda'), device(type='cuda', index=1)) 查询可用gpu的数量： torch.cuda.device_count() output: 4 现在定义了两个方便的函数，检查是否存在GPU，若存在返回所有的GPU def try_gpu(i=0): \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\" if torch.cuda.device_count() \u003e= i + 1: return torch.device(f'cuda:{i}') return torch.device('cpu') def try_all_gpus(): \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\" devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())] return devices if devices else [torch.device('cpu')] try_gpu(), try_gpu(10), try_all_gpus() output: (device(type='cuda', index=0), device(type='cpu'), [device(type='cuda', index=0)] [device(type='cuda', index=1)] [device(type='cuda', index=2)] [device(type='cuda', index=3)]) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:5:1","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"张量与GPU 我们可以查询张量所在的设备。 默认情况下，张量是在CPU上创建的。 x = torch.tensor([1, 2, 3]) x.device output: device(type='cpu') 需要注意的是，无论何时我们要对多个项进行操作，它们都必须在同一个设备上。例如，如果我们对两个张量求和，我们需要确保两个张量都位于同一个设备上，否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。 存储在GPU上 有几种方法可以在GPU上存储张量。例如，可以在创建张量时指定存储设备。接下来，在第一个gpu上创建张量变量X。在GPU上创建的张量只消耗这个GPU的显存。我们可以使用nvidia-smi命令查看显存使用情况。一般来说，我们需要确保不创建超过GPU显存限制的数据。 X = torch.ones(2, 3, device=try_gpu()) X output: tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:0') 假设我们至少有两个GPU，下面的代码将在第二个GPU上创建一个随机张量。 Y = torch.rand(2, 3, device=try_gpu(1)) Y output: tensor([[0.4860, 0.1285, 0.0440], [0.9743, 0.4159, 0.9979]], device='cuda:1') 复制 如果我们要计算X + Y，我们需要决定在哪里执行这个操作。例如，如下图所示，我们可以将X传输到第二个GPU并在那里执行操作。不要简单地X加上Y，因为这会导致异常，运行时引擎不知道该怎么做：它在同一设备上找不到数据会导致失败。由于Y位于第二个GPU上，所以我们需要将X移到那里，然后才能执行相加运算。 Z = X.cuda(1) print(X) print(Z) output: tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:0') tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:1') 现在数据在同一个GPU上（Z和Y都在），可以将它们相加。 Y + Z output: tensor([[1.4860, 1.1285, 1.0440], [1.9743, 1.4159, 1.9979]], device='cuda:1') 假设变量Z已经存在于第二个GPU上。如果还是调用Z.cuda(1)， 它将返回Z而不会复制并分配新内存。 Z.cuda(1) is Z output: True ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:5:2","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"神经网络与GPU 类似地，神经网络模型可以指定设备，下面的代码将模型参数放在GPU上： net = nn.Sequential(nn.Linear(3, 1)) net = net.to(device=try_gpu()) 当输入为GPU上的张量时，模型将在同一GPU上计算结果。 X = torch.ones(2, 3, device=try_gpu()) net(X) output: tensor([[-0.4275], [-0.4275]], device='cuda:0', grad_fn=\u003cAddmmBackward0\u003e) 下面代码可以确认模型参数是否存储在同一个GPU上： net[0].weight.data.device output: device(type='cuda', index=0) ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:5:3","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"补充 torch.rand()：构造均匀分布张量的方法 torch.rand是用于生成均匀随机分布张量的函数，从区间[0,1)的均匀分布中随机抽取一个随机数生成一个张量。 torch.randn()：构造标准正态分布张量的方法 torch.randn()是用于生成正态随机分布张量的函数，从标准正态分布中随机抽取一个随机数生成一个张量。 torch.randint()：构造区间分布张量的方法 torch.randint()是用于生成任意区间分布张量的函数，从该区间的均匀分布中随机抽取一个随机数生成一个张量。 ","date":"2023-10-29","objectID":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/:6:0","tags":["d2l","pytorch"],"title":"5 深度学习计算","uri":"/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/"},{"categories":["动手学深度学习"],"content":"多层感知机 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:1:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"隐藏层 如果我们的标签通过仿射变换后确实与我们的输入数据相关，那么这种方法确实足够了。 但是，仿射变换中的线性是一个很强的假设。线性意味着单调假设： 任何特征的增大都会导致模型输出的增大（如果对应的权重为正）， 或者导致模型输出的减小（如果对应的权重为负）。对线性模型的依赖对应于一个隐含的假设， 即区分猫和狗的唯一要求是评估单个像素的强度。 对于深度神经网络，需要使用观测数据来联合学习隐藏层表示和应用于该表示的线性预测器。 可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型。要做到这一点，最简单的方法是将许多全连接层堆叠在一起。每一层都输出到上面的层，直到生成最后的输出。可以把前$L-1$层看作表示，把最后一层看作线性预测器。这种架构通常称为多层感知机（multilayer perceptron），通常缩写为MLP。如下图： 这个多层感知机有4个输入，3个输出，其隐藏层包含5个隐藏单元。输入层不涉及任何计算，因此使用此网络产生输出只需要实现隐藏层和输出层的计算。因此，这个多层感知机中的层数为2。这两个层都是全连接的，每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元。 然而，具有全连接层的多层感知机的参数开销可能会高得令人望而却步。即使在不改变输入或输出大小的情况下，可能在参数节约和模型有效性之间进行权衡 我们通过矩阵$\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$来表示$n$个样本的小批量，其中每个样本具有$d$个输入特征。对于具有$h$个隐藏单元的单隐藏层多层感知机，用$\\mathbf{H} \\in \\mathbb{R}^{n \\times h}$表示隐藏层的输出，称为隐藏表示（hidden representations）。在数学或代码中，$\\mathbf{H}$也被称为隐藏层变量（hidden-layer variable）或隐藏变量（hidden variable）。因为隐藏层和输出层都是全连接的，所以有隐藏层权重$\\mathbf{W}^{(1)} \\in \\mathbb{R}^{d \\times h}$和隐藏层偏置$\\mathbf{b}^{(1)} \\in \\mathbb{R}^{1 \\times h}$以及输出层权重$\\mathbf{W}^{(2)} \\in \\mathbb{R}^{h \\times q}$和输出层偏置$\\mathbf{b}^{(2)} \\in \\mathbb{R}^{1 \\times q}$。形式上，我们按如下方式计算单隐藏层多层感知机的输出$\\mathbf{O} \\in \\mathbb{R}^{n \\times q}$： $$ \\begin{aligned} \\mathbf{H} \u0026 = \\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)}, \\ \\mathbf{O} \u0026 = \\mathbf{H}\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}. \\end{aligned} $$ 在添加隐藏层之后，模型现在需要跟踪和更新额外的参数。可我们能从中得到什么好处呢？在上面定义的模型里，我们没有好处！原因很简单：上面的隐藏单元由输入的仿射函数给出，而输出（softmax操作前）只是隐藏单元的仿射函数。仿射函数的仿射函数本身就是仿射函数，但是我们之前的线性模型已经能够表示任何仿射函数。 可以证明这一等价性，即对于任意权重值，我们只需合并隐藏层，便可产生具有参数$\\mathbf{W} = \\mathbf{W}^{(1)}\\mathbf{W}^{(2)}$和$\\mathbf{b} = \\mathbf{b}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}$的等价单层模型： $$ \\mathbf{O} = (\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)} = \\mathbf{X} \\mathbf{W}^{(1)}\\mathbf{W}^{(2)} + \\mathbf{b}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)} = \\mathbf{X} \\mathbf{W} + \\mathbf{b}. $$ 为了发挥多层架构的潜力，我们还需要一个额外的关键要素：在仿射变换之后对每个隐藏单元应用非线性的激活函数（activation function）$\\sigma$。激活函数的输出（例如，$\\sigma(\\cdot)$）被称为活性值（activations）。一般来说，有了激活函数，就不可能再将多层感知机退化成线性模型： $$ \\begin{aligned} \\mathbf{H} \u0026 = \\sigma(\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)}), \\\\ \\mathbf{O} \u0026 = \\mathbf{H}\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}.\\\\ \\end{aligned} $$ 由于$\\mathbf{X}$中的每一行对应于小批量中的一个样本，出于记号习惯的考量，我们定义非线性函数$\\sigma$也以按行的方式作用于其输入，即一次计算一个样本。但是本节应用于隐藏层的激活函数通常不仅按行操作，也按元素操作。这意味着在计算每一层的线性部分之后，可以计算每个活性值，而不需要查看其他隐藏单元所取的值。对于大多数激活函数都是这样。 为了构建更通用的多层感知机，可以继续堆叠这样的隐藏层，例如$\\mathbf{H}^{(1)} = \\sigma_1(\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})$和$\\mathbf{H}^{(2)} = \\sigma_2(\\mathbf{H}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)})$，一层叠一层，从而产生更有表达能力的模型。 虽然一个单隐层网络能学习任何函数， 但并不意味着应该尝试使用单隐藏层网络来解决所有问题。 事实上，通过使用更深（而不是更广）的网络，可以更容易地逼近许多函数。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:1:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"激活函数 激活函数（activation function）通过计算加权和并加上偏置来确定神经元是否应该被激活， 它们将输入信号转换为输出的可微运算。 大多数激活函数都是非线性的。 ReLU函数 最受欢迎的激活函数是修正线性单元（Rectified linear unit，ReLU）， 因为它实现简单，同时在各种预测任务中表现良好。 ReLU提供了一种非常简单的非线性变换。 给定元素$0$，ReLU函数被定义为该元素与0的最大值： $$ \\operatorname{ReLU}(x) = \\max(x, 0) $$ ReLU函数通过将相应的活性值设为0，仅保留正元素并丢弃所有负元素。 x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True) y = torch.relu(x) d2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5)) 当输入为负时，ReLU函数的导数为0，而当输入为正时，ReLU函数的导数为1。 y.backward(torch.ones_like(x), retain_graph=True) d2l.plot(x.detach(), x.grad, 'x', 'grad of relu', figsize=(5, 2.5)) 使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。 这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题。 ReLU函数有许多变体，包括参数化ReLU（Parameterized ReLU，pReLU）函数。 该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过： $$ \\operatorname{pReLU}(x) = \\max(0, x) + \\alpha \\min(0, x) $$ sigmoid函数 对于一个定义域在$\\mathbb{R}$中的输入，sigmoid函数将输入变换为区间(0, 1)上的输出。因此，sigmoid通常称为挤压函数（squashing function）：它将范围（-inf, inf）中的任意输入压缩到区间（0, 1）中的某个值： $$ \\operatorname{sigmoid}(x) = \\frac{1}{1 + \\exp(-x)} $$ 当人们逐渐关注到到基于梯度的学习时，sigmoid函数是一个自然的选择，因为它是一个平滑的、可微的阈值单元近似。当想要将输出视作二元分类问题的概率时，sigmoid仍然被广泛用作输出单元上的激活函数，然而，sigmoid在隐藏层中已经较少使用，它在大部分时候被更简单、更容易训练的ReLU所取代。 下面绘制sigmoid函数，输入接近0时，sigmoid函数接近线性变换。 y = torch.sigmoid(x) d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5)) sigmoid函数的导数为下面的公式： $$ \\frac{d}{dx} \\operatorname{sigmoid}(x) = \\frac{\\exp(-x)}{(1 + \\exp(-x))^2} = \\operatorname{sigmoid}(x)\\left(1-\\operatorname{sigmoid}(x)\\right) $$ sigmoid函数的导数图像如下所示。 当输入为0时，sigmoid函数的导数达到最大值0.25； 而输入在任一方向上越远离0点时，导数越接近0。 # 清除以前的梯度 x.grad.data.zero_() y.backward(torch.ones_like(x),retain_graph=True) d2l.plot(x.detach(), x.grad, 'x', 'grad of sigmoid', figsize=(5, 2.5)) tanh函数 与sigmoid函数类似， tanh(双曲正切)函数也能将其输入压缩转换到区间(-1, 1)上。 tanh函数的公式如下： $$ \\operatorname{tanh}(x) = \\frac{1 - \\exp(-2x)}{1 + \\exp(-2x)} $$ 当输入在0附近时，tanh函数接近线性变换。函数的形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。 y = torch.tanh(x) d2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5)) tanh函数的导数是： $$ \\frac{d}{dx} \\operatorname{tanh}(x) = 1 - \\operatorname{tanh}^2(x) $$ 当输入接近0时，tanh函数的导数接近最大值1。 与我们在sigmoid函数图像中看到的类似， 输入在任一方向上越远离0点，导数越接近0。 # 清除以前的梯度 x.grad.data.zero_() y.backward(torch.ones_like(x),retain_graph=True) d2l.plot(x.detach(), x.grad, 'x', 'grad of tanh', figsize=(5, 2.5)) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:1:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"实现多层感知机 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"读取数据 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"初始化模型参数 Fashion-MNIST中的每个图像由$28 \\times 28 = 784$个灰度像素值组成。所有图像共分为10个类别。忽略像素之间的空间结构，我们可以将每个图像视为具有784个输入特征和10个类的简单分类数据集。首先，将实现一个具有单隐藏层的多层感知机，它包含256个隐藏单元。通常，我们选择2的若干次幂作为层的宽度。因为内存在硬件中的分配和寻址方式，这么做往往可以在计算上更高效。 num_inputs, num_outputs, num_hiddens = 784, 10, 256 W1 = nn.Parameter(torch.randn( num_inputs, num_hiddens, requires_grad=True) * 0.01) b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) W2 = nn.Parameter(torch.randn( num_hiddens, num_outputs, requires_grad=True) * 0.01) b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True)) params = [W1, b1, W2, b2] ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"激活函数 这里实现ReLU激活函数， 而不是直接调用内置的relu函数。 def relu(X): a = torch.zeros_like(X) return torch.max(X, a) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:3","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"模型 由于忽略了空间结构， 所以使用reshape将每个二维图像转换为一个长度为num_inputs的向量。 def net(X): X = X.reshape((-1, num_inputs)) H = relu(X@W1 + b1) # 这里“@”代表矩阵乘法 return (H@W2 + b2) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:4","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"损失函数 这里使用高级API中的内置函数来计算softmax和交叉熵损失。 loss = nn.CrossEntropyLoss(reduction='none') ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:5","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"训练 多层感知机的训练过程与softmax回归的训练过程完全相同。 可以直接调用d2l包的train_ch3函数， 将迭代周期数设置为10，并将学习率设置为0.1。 num_epochs, lr = 10, 0.1 updater = torch.optim.SGD(params, lr=lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:6","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"使用深度学习框架简洁实现多层感知机 与softmax回归的简洁实现相比， 唯一的区别是添加了2个全连接层（之前只添加了1个全连接层）。 第一层是隐藏层，它包含256个隐藏单元，并使用了ReLU激活函数，第二层是输出层。 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); 训练过程的实现与实现softmax回归时完全相同。 batch_size, lr, num_epochs = 256, 0.1, 10 loss = nn.CrossEntropyLoss(reduction='none') trainer = torch.optim.SGD(net.parameters(), lr=lr) train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:3:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"模型选择、欠拟合和过拟合 我们的目标是发现某些模式， 这些模式捕捉到了我们训练集潜在总体的规律。 如果成功做到了这点，即使是对以前从未遇到过的个体， 模型也可以成功地评估风险。 如何发现可以泛化的模式是机器学习的根本问题。将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting）， 用于对抗过拟合的技术称为正则化（regularization）。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:4:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"训练误差和泛化误差 训练误差（training error）是指， 模型在训练数据集上计算得到的误差。 泛化误差（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由随机选取的、未曾在训练集中出现的数据样本构成。 模型复杂性 本节为了给出一些直观的印象，将重点介绍几个倾向于影响模型泛化的因素。 可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:4:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"模型选择 在机器学习中，我们通常在评估几个候选模型后选择最终的模型，这个过程叫做模型选择。 有时需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）；又有时，我们需要比较不同的超参数设置下的同一类模型，例如，训练多层感知机模型时，我们可能希望比较具有不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。为了确定候选模型中的最佳模型，我们通常会使用验证集。 验证集 原则上，在确定所有的超参数之前，我们不希望用到测试集。 如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。如果过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。 但是如果过拟合了测试数据，就无法知道了。因此，决不能依靠测试数据进行模型选择。 然而，也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。 解决此问题的常见做法是将数据分成三份，除了训练和测试数据集之外，还增加一个验证数据集（validation dataset），也叫验证集（validation set）。 K折交叉验证 当训练数据稀缺时，甚至可能无法提供足够的数据来构成一个合适的验证集。这个问题的一个流行的解决方案是采用$K$折交叉验证。这里，原始训练数据被分成$K$个不重叠的子集。然后执行$K$次模型训练和验证，每次在$K-1$个子集上进行训练，并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。最后，通过对$K$次实验的结果取平均来估计训练和验证误差。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:4:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"欠拟合和过拟合 当比较训练和验证误差时，要注意两种常见的情况。 ①训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足），无法捕获试图学习的模式。此外，由于训练和验证误差之间的泛化误差很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为欠拟合（underfitting）；②当训练误差明显低于验证误差时表明严重的过拟合（overfitting）。 注意，过拟合并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终通常更关心验证误差，而不是训练误差和验证误差之间的差距。 是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小。 模型复杂度 例子：给定由单个特征$x$和对应实数标签$y$组成的训练数据，试图找到下面的$d$阶多项式来估计标签$y$。 $$ \\hat{y}= \\sum_{i=0}^d x^i w_i $$ 这只是一个线性回归问题，特征是$x$的幂给出的，模型的权重是$w_i$给出的，偏置是$w_0$给出的（因为对于所有的$x$都有$x^0 = 1$）。 由于这只是一个线性回归问题，我们可以使用平方误差作为我们的损失函数。高阶多项式函数比低阶多项式函数复杂得多。高阶多项式的参数较多，模型函数的选择范围较广。因此在固定训练数据集的情况下，高阶多项式函数相对于低阶多项式的训练误差应该始终更低（最坏也是相等）。事实上，当数据样本包含了$x$的不同值时，函数阶数等于数据样本数量的多项式函数可以完美拟合训练集。 如下图直观地描述了多项式的阶数和欠拟合与过拟合之间的关系。 数据集大小 另一个重要因素是数据集的大小。 训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。一般来说，更多的数据不会有什么坏处。对于固定的任务和数据分布，模型复杂性和数据集大小之间通常存在关系。给出更多的数据，可能会尝试拟合一个更复杂的模型。能够拟合更复杂的模型可能是有益的。如果没有足够的数据，简单的模型可能更有用。对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:4:3","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"多项式回归 生成数据集 给定$x$，下面将使用以下三阶多项式来生成训练和测试数据的标签： $$ y = 5 + 1.2x - 3.4\\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\text{ where } \\epsilon \\sim \\mathcal{N}(0, 0.1^2) $$ 噪声项$\\epsilon$服从均值为0且标准差为0.1的正态分布。在优化的过程中，通常希望避免非常大的梯度值或损失值。这就是将特征从$x^i$调整为$\\frac{x^i}{i!}$的原因，这样可以避免很大的$i$带来的特别大的指数值。为训练集和测试集各生成100个样本。 max_degree = 20 # 多项式的最大阶数 n_train, n_test = 100, 100 # 训练和测试数据集大小 true_w = np.zeros(max_degree) # 分配大量的空间 true_w[0:4] = np.array([5, 1.2, -3.4, 5.6]) features = np.random.normal(size=(n_train + n_test, 1)) np.random.shuffle(features) poly_features = np.power(features, np.arange(max_degree).reshape(1, -1)) # 求x的幂 for i in range(max_degree): poly_features[:, i] /= math.gamma(i + 1) # gamma(n)=(n-1)! # labels的维度:(n_train+n_test,) labels = np.dot(poly_features, true_w) labels += np.random.normal(scale=0.1, size=labels.shape) 存储在poly_features中的单项式由gamma函数重新缩放，其中$\\Gamma(n)=(n-1)!$。 # NumPy ndarray转换为tensor true_w, features, poly_features, labels = [torch.tensor(x, dtype= torch.float32) for x in [true_w, features, poly_features, labels]] features[:2], poly_features[:2, :], labels[:2] output: (tensor([[0.2680], [0.0072]]), tensor([[1.0000e+00, 2.6800e-01, 3.5911e-02, 3.2080e-03, 2.1493e-04, 1.1520e-05, 5.1456e-07, 1.9700e-08, 6.5994e-10, 1.9651e-11, 5.2664e-13, 1.2831e-14, 2.8655e-16, 5.9072e-18, 1.1308e-19, 2.0203e-21, 3.3840e-23, 5.3346e-25, 7.9426e-27, 1.1203e-28], [1.0000e+00, 7.1886e-03, 2.5838e-05, 6.1913e-08, 1.1127e-10, 1.5997e-13, 1.9166e-16, 1.9682e-19, 1.7686e-22, 1.4126e-25, 1.0155e-28, 6.6363e-32, 3.9755e-35, 2.1983e-38, 1.1287e-41, 5.6052e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), tensor([5.1112, 4.9042])) 训练和测试 实现一个函数来评估模型在给定数据集上的损失。 def evaluate_loss(net, data_iter, loss): #@save \"\"\"评估给定数据集上模型的损失\"\"\" metric = d2l.Accumulator(2) # 损失的总和,样本数量 for X, y in data_iter: out = net(X) y = y.reshape(out.shape) l = loss(out, y) metric.add(l.sum(), l.numel()) return metric[0] / metric[1] 定义训练函数 def train(train_features, test_features, train_labels, test_labels, num_epochs=400): loss = nn.MSELoss(reduction='none') input_shape = train_features.shape[-1] # 不设置偏置，因为我们已经在多项式中实现了它 net = nn.Sequential(nn.Linear(input_shape, 1, bias=False)) batch_size = min(10, train_labels.shape[0]) train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)), batch_size) test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)), batch_size, is_train=False) trainer = torch.optim.SGD(net.parameters(), lr=0.01) animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log', xlim=[1, num_epochs], ylim=[1e-3, 1e2], legend=['train', 'test']) for epoch in range(num_epochs): d2l.train_epoch_ch3(net, train_iter, loss, trainer) if epoch == 0 or (epoch + 1) % 20 == 0: animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss), evaluate_loss(net, test_iter, loss))) print('weight:', net[0].weight.data.numpy()) 三阶多项式函数-正常拟合 首先使用三阶多项式函数，它与数据生成函数的阶数相同。结果表明，该模型能有效降低训练损失和测试损失。学习到的模型参数也接近真实值$w = [5, 1.2, -3.4, 5.6]$。 # 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3! train(poly_features[:n_train, :4], poly_features[n_train:, :4], labels[:n_train], labels[n_train:]) output: weight: [[ 4.994724 1.2322158 -3.36956 5.5164495]] 线性函数-欠拟合 再看线性函数拟合，减少该模型的训练损失相对困难。 在最后一个迭代周期完成后，训练损失仍然很高。 当用来拟合非线性模式（如这里的三阶多项式函数）时，线性模型容易欠拟合。 # 从多项式特征中选择前2个维度，即1和x train(poly_features[:n_train, :2], poly_features[n_train:, :2], labels[:n_train], labels[n_train:]) output: weight: [[3.3262606 3.4666014]] 高阶多项式函数-过拟合 尝试使用一个阶数过高的多项式来训练模型。在这种情况下，没有足够的数据用于学到高阶系数应该具有接近于零的值。因此，这个过于复杂的模型会轻易受到训练数据中噪声的影响。虽然训练损失可以有效地降低，但测试损失仍然很高。结果表明，复杂模型对数据造成了过拟合。 # 从多项式特征中选取所有维度 train(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=1500) output: weight: [[ 4.9849787 1.2896876 -3.2996354 5.145749 -0.34205326 1.2237961 0.20393135 0.3027379 -0.20079008 -0.16337848 0.11026663 0.21135856 -0.00940325 0.11873583 -0.15114897 -0.05347819 0.17096086 0.1863975 -0.09107699 -0.02123026]] ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:4:4","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"权重衰减 总是可以通过去收集更多的训练数据来缓解过拟合，但这可能成本很高，耗时颇多，或者完全超出控制，因而在短期内不可能做到。假设我们已经拥有尽可能多的高质量数据，我们便可以将重点放在正则化技术上。 即使是阶数上的微小变化，比如从2到3，也会显著增加模型的复杂性。仅仅通过简单的限制特征数量（在多项式回归中体现为限制阶数），可能仍然使模型在过简单和过复杂中徘徊， 我们需要一个更细粒度的工具来调整函数的复杂性，使其达到一个合适的平衡位置。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:5:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"范数与权重衰减 在训练参数化机器学习模型时，权重衰减（weight decay）是最广泛使用的正则化的技术之一，它通常也被称为$L_2$正则化。一种简单的方法是通过线性函数$f(\\mathbf{x}) = \\mathbf{w}^\\top \\mathbf{x}$中的权重向量的某个范数来度量其复杂性，例如$| \\mathbf{w} |^2$。要保证权重向量比较小，最常用方法是将其范数作为惩罚项加到最小化损失的问题中。将原来的训练目标最小化训练标签上的预测损失，调整为最小化预测损失和惩罚项之和。但如果我们的权重向量增长的太大，学习算法可能会更集中于最小化权重范数$| \\mathbf{w} |^2$。我们回顾一下线性回归中的损失函数： $$ L(\\mathbf{w}, b) = \\frac{1}{n}\\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2 $$ $\\mathbf{x}^{(i)}$是样本$i$的特征，$y^{(i)}$是样本$i$的标签，$(\\mathbf{w}, b)$是权重和偏置参数。为了惩罚权重向量的大小，必须以某种方式在损失函数中添加$| \\mathbf{w} |^2$。就通过正则化常数$\\lambda$来描述这种额外惩罚损失的平衡，这是一个非负超参数，我们使用验证数据拟合： $$ L(\\mathbf{w}, b) + \\frac{\\lambda}{2} |\\mathbf{w}|^2 $$ 对于$\\lambda = 0$，就恢复了原来的损失函数；对于$\\lambda \u003e 0$，就限制了$| \\mathbf{w} |$的大小。这里仍然除以$2$：因为取一个二次函数的导数时，$2$和$1/2$会抵消，以确保更新表达式看起来既漂亮又简单。这里使用平方范数而不是标准范数（即欧几里得距离）的原因：便于计算，通过平方$L_2$范数，去掉平方根，留下权重向量每个分量的平方和，这使得惩罚的导数很容易计算，导数的和就等于和的导数。 另外使用$L_2$范数，而不是$L_1$范数的原因：事实上，这个选择在整个统计领域中都是有效的和受欢迎的。$L_2$正则化线性模型构成经典的岭回归（ridge regression）算法，$L_1$正则化线性回归是统计学中类似的基本模型，通常被称为套索回归（lasso regression）。使用$L_2$范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。这使得学习算法偏向于在大量特征上均匀分布权重的模型。在实践中，这可能使它们对单个变量中的观测误差更为稳定。相比之下，$L_1$惩罚会导致模型将权重集中在一小部分特征上，而将其他权重清除为零。这称为特征选择（feature selection），可能是其他场景下需要的。 $L_2$正则化回归的小批量随机梯度下降更新如下式： $$ \\begin{aligned} \\mathbf{w} \u0026 \\leftarrow \\mathbf{w} - \\eta\\left[\\frac{1}{|\\mathcal{B}|}\\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right) + \\lambda\\mathbf{w} \\right] \\\\ \u0026 \\leftarrow \\left(1- \\eta\\lambda \\right) \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right). \\end{aligned} $$ 上述式子通常$\\eta\\lambda \u003c 1$，也就是先把$\\mathbf{w}$变小了一点，沿着梯度方向走一点。 这里根据估计值与观测值之间的差异来更新$\\mathbf{w}$，同时也在试图将$\\mathbf{w}$的大小缩小到零。这就是为什么这种方法有时被称为权重衰减。我们仅考虑惩罚项，优化算法在训练的每一步衰减权重。与特征选择相比，权重衰减为我们提供了一种连续的机制来调整函数的复杂度。较小的$\\lambda$值对应较少约束的$\\mathbf{w}$，而较大的$\\lambda$值对$\\mathbf{w}$的约束更大。 是否对相应的偏置$b^2$进行惩罚在不同的实践中会有所不同，在神经网络的不同层中也会有所不同。通常，网络输出层的偏置项不会被正则化。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:5:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"实现权重衰减 生成数据 通过一个简单的例子来演示权重衰减，首先，像以前一样生成一些数据，生成公式如下： $$ y = 0.05 + \\sum_{i = 1}^d 0.01 x_i + \\epsilon \\text{ where } \\epsilon \\sim \\mathcal{N}(0, 0.01^2) $$ 我们选择标签是关于输入的线性函数。标签同时被均值为0，标准差为0.01高斯噪声破坏。为了使过拟合的效果更加明显，我们可以将问题的维数增加到$d = 200$，并使用一个只包含20个样本的小训练集。 n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5 true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05 train_data = d2l.synthetic_data(true_w, true_b, n_train) train_iter = d2l.load_array(train_data, batch_size) test_data = d2l.synthetic_data(true_w, true_b, n_test) test_iter = d2l.load_array(test_data, batch_size, is_train=False) 初始化模型参数 定义一个函数来随机初始化模型参数 def init_params(): w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) return [w, b] 定义$L_2$范数惩罚 实现这一惩罚最方便的方法是对所有项求平方后并将它们求和。 def l2_penalty(w): return torch.sum(w.pow(2)) / 2 训练代码实现 线性网络和平方损失没有变化， 所以我们通过d2l.linreg和d2l.squared_loss导入它们。 唯一的变化是损失现在包括了惩罚项。 def train(lambd): w, b = init_params() net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr = 100, 0.003 animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test']) for epoch in range(num_epochs): for X, y in train_iter: # 增加了L2范数惩罚项， # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量 l = loss(net(X), y) + lambd * l2_penalty(w) l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print('w的L2范数是：', torch.norm(w).item()) 忽略正则化训练 用lambd = 0禁用权重衰减后运行这个代码。注意，这里训练误差有了减少，但测试误差没有减少，这意味着出现了严重的过拟合。 train(lambd=0) output: w的L2范数是： 13.156189918518066 使用权重衰减 下面，使用权重衰减来运行代码。注意，在这里训练误差增大，但测试误差减小。这正是我们期望从正则化中得到的效果。 train(lambd=3) output: w的L2范数是： 0.3738817870616913 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:5:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"简洁实现 由于权重衰减在神经网络优化中很常用，深度学习框架为了便于我们使用权重衰减，将权重衰减集成到优化算法中，以便与任何损失函数结合使用。此外，这种集成还有计算上的好处，允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。由于更新的权重衰减部分仅依赖于每个参数的当前值，因此优化器必须至少接触每个参数一次。 在下面的代码中，我们在实例化优化器时直接通过weight_decay指定weight decay超参数。默认情况下PyTorch同时衰减权重和偏移。这里我们只为权重设置了weight_decay，所以偏置参数$b$不会衰减。 def train_concise(wd): net = nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss = nn.MSELoss(reduction='none') num_epochs, lr = 100, 0.003 # 偏置参数没有衰减 trainer = torch.optim.SGD([ {\"params\":net[0].weight,'weight_decay': wd}, {\"params\":net[0].bias}], lr=lr) animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test']) for epoch in range(num_epochs): for X, y in train_iter: trainer.zero_grad() l = loss(net(X), y) l.mean().backward() trainer.step() if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print('w的L2范数：', net[0].weight.norm().item()) 上述代码不用太纠结loss函数是否有加上所说的$\\frac{\\lambda}{2} |\\mathbf{w}|^2$，这个罚主要是为了限制$\\mathbf{w}$学得太大。 train_concise(0) output: w的L2范数： 13.727912902832031 train_concise(3) output: w的L2范数： 0.3890590965747833 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:5:3","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"暂退法(Dropout) 暂退法的动机：一个好的模型需要对输入数据的扰动鲁棒。解决方法：具有输入噪声的训练等价于Tikhonov正则化，暂退法，即在层之间加入噪声。 暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术。暂退法从表面上看是在训练过程中丢弃（drop out）一些神经元，在整个训练过程的每一次迭代中，标准暂退法包括在计算下一层之前将当前层中的一些节点置零。 在每次训练迭代中，将从均值为零的分布$\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$采样噪声添加到输入$\\mathbf{x}$，从而产生扰动点$\\mathbf{x}’ = \\mathbf{x} + \\epsilon$，预期是$E[\\mathbf{x}’] = \\mathbf{x}$。 在标准暂退法正则化中，通过按保留（未丢弃）的节点的分数进行规范化来消除每一层的偏差。换言之，每个中间活性值$h$以暂退概率$p$由随机变量$h’$替换，如下所示： $$ \\begin{aligned} h’ = \\begin{cases} 0 \u0026 \\text{ ，概率为 } p \\\\ \\frac{h}{1-p} \u0026 \\text{ ，其他情况} \\end{cases} \\end{aligned} $$ 根据此模型的设计，其期望值保持不变，即$E[h’] = h$。 当我们将暂退法应用到多层感知机的隐藏层，以$p$的概率将隐藏单元置为零时。比如在下图中删除了$h_2$和$h_5$，那么输出的计算不再依赖于$h_2$或$h_5$，并且它们各自的梯度在执行反向传播时也会消失。这样，输出层的计算不能过度依赖于$h_1, \\ldots, h_5$的任何一个元素。 $$\r\\begin{aligned}\r\\mathbf{h} \u0026 = \\sigma(\\mathbf{W_1} \\mathbf{X} + \\mathbf{b_1}) \\\\\\\r\\mathbf{h'} \u0026 = \\mathbf{dropout}(\\mathbf{h}) \\\\\\\r\\mathbf{o} \u0026 = \\mathbf{W_2} \\mathbf{h'} + \\mathbf{b_2}\\\\\\\r\\mathbf{y} \u0026= \\mathbf{softmax}(\\mathbf{o})\r\\end{aligned}\r$$\r通常，在测试时不用暂退法。正则项只在训练中使用，且常作用在多层感知机的隐藏层输出上，因为他们影响模型参数的更新，在预测中不需要修改模型参数，因此不需要正则项。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:6:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"实现Dropout 下面代码实现 dropout_layer 函数，该函数以dropout的概率丢弃张量输入X中的元素，如上所述重新缩放剩余部分：将剩余部分除以1.0-dropout。 def dropout_layer(X, dropout): assert 0 \u003c= dropout \u003c= 1 # 在本情况中，所有元素都被丢弃 if dropout == 1: return torch.zeros_like(X) # 在本情况中，所有元素都被保留 if dropout == 0: return X mask = (torch.rand(X.shape) \u003e dropout).float() #rand生成0-1的均匀分布，若生成的数大于dropout则是1，否则是0 return mask * X / (1.0 - dropout) 测试dropout_layer函数。将输入X通过暂退法操作，暂退概率分别为0、0.5和1。 X= torch.arange(16, dtype = torch.float32).reshape((2, 8)) print(X) print(dropout_layer(X, 0.)) print(dropout_layer(X, 0.5)) print(dropout_layer(X, 1.)) output: tensor([[ 0., 1., 2., 3., 4., 5., 6., 7.], [ 8., 9., 10., 11., 12., 13., 14., 15.]]) tensor([[ 0., 1., 2., 3., 4., 5., 6., 7.], [ 8., 9., 10., 11., 12., 13., 14., 15.]]) tensor([[ 0., 2., 4., 6., 0., 0., 12., 0.], [16., 0., 20., 22., 24., 26., 28., 0.]]) tensor([[0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0.]]) 定义模型，定义具有两个隐藏层的多层感知机，我们可以将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。下面的模型将第一个和第二个隐藏层的暂退概率分别设置为0.2和0.5，并且暂退法只在训练期间有效。 num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256 dropout1, dropout2 = 0.2, 0.5 class Net(nn.Module): def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = True): super(Net, self).__init__() self.num_inputs = num_inputs self.training = is_training self.lin1 = nn.Linear(num_inputs, num_hiddens1) self.lin2 = nn.Linear(num_hiddens1, num_hiddens2) self.lin3 = nn.Linear(num_hiddens2, num_outputs) self.relu = nn.ReLU() def forward(self, X): H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs)))) # 只有在训练模型时才使用dropout if self.training == True: # 在第一个全连接层之后添加一个dropout层 H1 = dropout_layer(H1, dropout1) H2 = self.relu(self.lin2(H1)) if self.training == True: # 在第二个全连接层之后添加一个dropout层 H2 = dropout_layer(H2, dropout2) out = self.lin3(H2) return out net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2) 训练和测试 num_epochs, lr, batch_size = 10, 0.5, 256 loss = nn.CrossEntropyLoss(reduction='none') train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) trainer = torch.optim.SGD(net.parameters(), lr=lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 简洁实现Dropout net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), # 在第一个全连接层之后添加一个dropout层 nn.Dropout(dropout1), nn.Linear(256, 256), nn.ReLU(), # 在第二个全连接层之后添加一个dropout层 nn.Dropout(dropout2), nn.Linear(256, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); 训练和测试 trainer = torch.optim.SGD(net.parameters(), lr=lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:6:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"前向传播、反向传播和计算图 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:7:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"前向传播 前向传播（forward propagation或forward pass） 指的是：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。 为了简单起见，假设输入样本是 $\\mathbf{x}\\in \\mathbb{R}^d$，并且隐藏层不包括偏置项。这里的中间变量是：$\\mathbf{z}= \\mathbf{W}^{(1)} \\mathbf{x}$，其中$\\mathbf{W}^{(1)} \\in \\mathbb{R}^{h \\times d}$是隐藏层的权重参数。将中间变量$\\mathbf{z}\\in \\mathbb{R}^h$通过激活函数$\\phi$后，得到长度为$h$的隐藏激活向量：$\\mathbf{h}= \\phi (\\mathbf{z})$，隐藏变量$\\mathbf{h}$也是一个中间变量。假设输出层的参数只有权重$\\mathbf{W}^{(2)} \\in \\mathbb{R}^{q \\times h}$，我们可以得到输出层变量，它是一个长度为$q$的向量：$\\mathbf{o}= \\mathbf{W}^{(2)} \\mathbf{h}$。假设损失函数为$l$，样本标签为$y$，可以计算单个数据样本的损失项，$L = l(\\mathbf{o}, y)$。根据$L_2$正则化的定义，给定超参数$\\lambda$，正则化项为$s = \\frac{\\lambda}{2} \\left(|\\mathbf{W}^{(1)}|_F^2 + |\\mathbf{W}^{(2)}|_F^2\\right)$，其中矩阵的Frobenius范数是将矩阵展平为向量后应用的$L_2$范数。最后，模型在给定数据样本上的正则化损失为：$J = L + s$，在下面的讨论中，会将$J$称为目标函数（objective function）。 下图是前向传播计算图，其中正方形表示变量，圆圈表示操作符。左下角表示输入，右上角表示输出。注意显示数据流的箭头方向主要是向右和向上的。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:7:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"反向传播 反向传播（backward propagation或backpropagation）指的是计算神经网络参数梯度的方法。简言之，该方法根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络。该算法存储了计算某些参数梯度时所需的任何中间变量（偏导数）。假设有函数$\\mathsf{Y}=f(\\mathsf{X})$和$\\mathsf{Z}=g(\\mathsf{Y})$，其中输入和输出$\\mathsf{X}, \\mathsf{Y}, \\mathsf{Z}$是任意形状的张量。利用链式法则，可以计算$\\mathsf{Z}$关于$\\mathsf{X}$的导数 $$ \\frac{\\partial \\mathsf{Z}}{\\partial \\mathsf{X}} = \\text{prod}\\left(\\frac{\\partial \\mathsf{Z}}{\\partial \\mathsf{Y}}, \\frac{\\partial \\mathsf{Y}}{\\partial \\mathsf{X}}\\right) $$ 在这里，$\\text{prod}$运算符在执行必要的操作（如换位和交换输入位置）后将其参数相乘。对于向量，它只是矩阵-矩阵乘法。对于高维张量，我们使用适当的对应项。运算符$\\text{prod}$指代了所有的这些符号。 在计算图7-1中的单隐藏层简单网络的参数是$\\mathbf{W}^{(1)}$和$\\mathbf{W}^{(2)}$，反向传播的目的是计算梯度$\\partial J/\\partial \\mathbf{W}^{(1)}$和$\\partial J/\\partial \\mathbf{W}^{(2)}$。为此，应用链式法则，依次计算每个中间变量和参数的梯度。计算的顺序与前向传播中执行的顺序相反，因为需要从计算图的结果开始，并朝着参数的方向努力。第一步是计算目标函数$J=L+s$相对于损失项$L$和正则项$s$的梯度。 $$ \\frac{\\partial J}{\\partial L} = 1 ; \\text{and} ; \\frac{\\partial J}{\\partial s} = 1 $$ 接下来，根据链式法则计算目标函数关于输出层变量$\\mathbf{o}$的梯度： $$ \\frac{\\partial J}{\\partial \\mathbf{o}} = \\text{prod}\\left(\\frac{\\partial J}{\\partial L}, \\frac{\\partial L}{\\partial \\mathbf{o}}\\right) = \\frac{\\partial L}{\\partial \\mathbf{o}} \\in \\mathbb{R}^q $$ 接下来，计算正则化项相对于两个参数的梯度： $$ \\frac{\\partial s}{\\partial \\mathbf{W}^{(1)}} = \\lambda \\mathbf{W}^{(1)} ; \\text{and} ; \\frac{\\partial s}{\\partial \\mathbf{W}^{(2)}} = \\lambda \\mathbf{W}^{(2)} $$ 现在可以计算最接近输出层的模型参数的梯度$\\partial J/\\partial \\mathbf{W}^{(2)} \\in \\mathbb{R}^{q \\times h}$。使用链式法则得出： $$ \\frac{\\partial J}{\\partial \\mathbf{W}^{(2)}}= \\text{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{W}^{(2)}}\\right) + \\text{prod}\\left(\\frac{\\partial J}{\\partial s}, \\frac{\\partial s}{\\partial \\mathbf{W}^{(2)}}\\right)= \\frac{\\partial J}{\\partial \\mathbf{o}} \\mathbf{h}^\\top + \\lambda \\mathbf{W}^{(2)} $$ 为了获得关于$\\mathbf{W}^{(1)}$的梯度，我们需要继续沿着输出层到隐藏层反向传播。关于隐藏层输出的梯度$\\partial J/\\partial \\mathbf{h} \\in \\mathbb{R}^h$由下式给出： $$ \\frac{\\partial J}{\\partial \\mathbf{h}} = \\text{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{h}}\\right) = {\\mathbf{W}^{(2)}}^\\top \\frac{\\partial J}{\\partial \\mathbf{o}} $$ 由于激活函数$\\phi$是按元素计算的，计算中间变量$\\mathbf{z}$的梯度$\\partial J/\\partial \\mathbf{z} \\in \\mathbb{R}^h$需要使用按元素乘法运算符，我们用$\\odot$表示： $$ \\frac{\\partial J}{\\partial \\mathbf{z}} = \\text{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{h}}, \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z}}\\right) = \\frac{\\partial J}{\\partial \\mathbf{h}} \\odot \\phi’\\left(\\mathbf{z}\\right) $$ 最后，可以得到最接近输入层的模型参数的梯度$\\partial J/\\partial \\mathbf{W}^{(1)} \\in \\mathbb{R}^{h \\times d}$。根据链式法则，我们得到： $$ \\frac{\\partial J}{\\partial \\mathbf{W}^{(1)}} = \\text{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{z}}, \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}^{(1)}}\\right) + \\text{prod}\\left(\\frac{\\partial J}{\\partial s}, \\frac{\\partial s}{\\partial \\mathbf{W}^{(1)}}\\right) = \\frac{\\partial J}{\\partial \\mathbf{z}} \\mathbf{x}^\\top + \\lambda \\mathbf{W}^{(1)} $$ ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:7:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"训练神经网络 在训练神经网络时，前向传播和反向传播相互依赖。对于前向传播，我们沿着依赖的方向遍历计算图并计算其路径上的所有变量。然后将这些用于反向传播，其中计算顺序与计算图的相反。 以上述简单网络为例：一方面，前向传播期间计算正则项取决于模型参数$\\mathbf{W}^{(1)}$和$\\mathbf{W}^{(2)}$的当前值。它们是由优化算法根据最近迭代的反向传播给出的。另一方面，反向传播期间参数(公式94)的梯度计算，取决于由前向传播给出的隐藏变量$\\mathbf{h}$的当前值。 因此，在训练神经网络时，在初始化模型参数后，需要交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。注意，反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。这也是训练比单纯的预测需要更多的内存（显存）的原因之一。此外，这些中间值的大小与网络层的数量和批量的大小大致成正比。因此，使用更大的批量来训练更深层次的网络更容易导致内存不足（out of memory）错误。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:7:3","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"数值稳定性和模型初始化 初始化方案的选择在神经网络学习中起着举足轻重的作用，它对保持数值稳定性至关重要。此外，这些初始化方案的选择可以与非线性激活函数的选择有趣的结合在一起。我们选择哪个函数以及如何初始化参数可以决定优化算法收敛的速度有多快，糟糕选择可能会导致在训练时遇到梯度爆炸或梯度消失。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:8:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"梯度消失和梯度爆炸 上图为神经网络的梯度计算，可以看到最后会有许多的矩阵乘法，这会带来一些问题。 梯度消失 激活函数sigmoid函数$1/(1 + \\exp(-x))$，它会导致梯度消失问题。 x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True) y = torch.sigmoid(x) y.backward(torch.ones_like(x)) d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()], legend=['sigmoid', 'gradient'], figsize=(4.5, 2.5)) 正如上图，当sigmoid函数的输入很大或是很小时，它的梯度都会消失。 此外，当反向传播通过许多层时，除非我们在刚刚好的地方， 这些地方sigmoid函数的输入接近于零，否则整个乘积的梯度可能会消失。 当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。 梯度消失的问题： 梯度值变成0 对16位浮点数尤为严重 训练没有进展 不管如何选择学习率 对于底部层尤为严重 仅仅顶部层训练的较好 无法让神经网络更深 梯度爆炸 相反，梯度爆炸可能同样令人烦恼。我们生成100个高斯随机矩阵，并将它们与某个初始矩阵相乘。对于我们选择的尺度（方差$\\sigma^2=1$），矩阵乘积发生爆炸。当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。 M = torch.normal(0, 1, size=(4,4)) print('一个矩阵 \\n',M) for i in range(100): M = torch.mm(M, torch.normal(0, 1, size=(4, 4))) print('乘以100个矩阵后\\n', M) output: 一个矩阵 tensor([[ 0.1969, 0.9725, 0.0580, -0.7313], [-0.1515, 0.3700, 2.4064, -0.8915], [ 0.3983, 0.0538, 0.9967, -1.4327], [-0.7009, 1.2494, -0.2294, 1.3601]]) 乘以100个矩阵后 tensor([[ 6.9463e+25, -6.1771e+25, 1.6948e+26, -1.7734e+26], [ 9.6462e+25, -8.5781e+25, 2.3535e+26, -2.4627e+26], [ 5.9542e+25, -5.2949e+25, 1.4527e+26, -1.5201e+26], [ 2.8045e+25, -2.4939e+25, 6.8424e+25, -7.1598e+25]]) 梯度爆炸的问题： 值超出值域(infinity) 对于16位浮点数尤为严重(数值区间6e-5 - 6e4) 对学习率敏感 如果学习率太大 -\u003e 大参数值 -\u003e 更大梯度 如果学习率太小 -\u003e 训练无进展 我么可能需要在训练过程不断调整学习率 打破对称性 神经网络设计中的另一个问题是其参数化所固有的对称性。假设有一个简单的多层感知机，它有一个隐藏层和两个隐藏单元。在这种情况下，我们可以对第一层的权重$\\mathbf{W}^{(1)}$进行重排列，并且同样对输出层的权重进行重排列，可以获得相同的函数。第一个隐藏单元与第二个隐藏单元没有什么特别的区别。换句话说，在每一层的隐藏单元之间具有排列对称性。 假设输出层将上述两个隐藏单元的多层感知机转换为仅一个输出单元。如果将隐藏层的所有参数初始化为$\\mathbf{W}^{(1)} = c$，$c$为常量，在这种情况下，在前向传播期间，两个隐藏单元采用相同的输入和参数，产生相同的激活，该激活被送到输出单元。在反向传播期间，根据参数$\\mathbf{W}^{(1)}$对输出单元进行微分，得到一个梯度，其元素都取相同的值。因此，在基于梯度的迭代（例如，小批量随机梯度下降）之后，$\\mathbf{W}^{(1)}$的所有元素仍然采用相同的值。这样的迭代永远不会打破对称性，我们可能永远也无法实现网络的表达能力。隐藏层的行为就好像只有一个单元。请注意，虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:8:1","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"参数初始化 解决（或至少减轻）上述问题的一种方法是进行参数初始化，优化期间的注意和适当的正则化也可以进一步提高稳定性。 权重初始化需要注意的地方： 在合理值区间里随机初始化参数 训练开始的时候更容易有数值不稳定 远离最优解的地方损失函数表面可能很复杂 最优解附近表面会比较平 使用$\\mathbf{N}(0,0.01)$来初始可能对小网络没问题，但不能保证深度神经网络 如果我们不指定初始化方法， 框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。 Xavier初始化：权重初始化时的方差是根据输入和输出维度来定的 希望让每一层输出的方差和梯度的方差是一个常数 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:8:2","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"环境和分布偏移 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:9:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"实战Kaggle比赛：预测房价 预测房价 ","date":"2023-10-29","objectID":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:10:0","tags":["d2l","pytorch"],"title":"4 多层感知机","uri":"/4-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["动手学深度学习"],"content":"线性回归 在机器学习领域中的大多数任务通常都与预测（prediction）有关。 当我们想预测一个数值时，就会涉及到回归问题。 我们希望根据房屋的面积（平方英尺）和房龄（年）来估算房屋价格（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为训练数据集或训练集。 每行数据（比如一次房屋交易相对应的数据）称为样本（sample）， 也可以称为数据点（data point）或数据样本（data instance）。 我们把试图预测的目标（比如预测房屋价格）称为标签（label）或目标（target）。 预测所依据的自变量（面积和房龄）称为特征（feature）或协变量（covariate）。 通常，使用$n$来表示数据集中的样本数。对索引为$i$的样本，其输入表示为$\\mathbf{x}^{(i)} = [x_1^{(i)}, x_2^{(i)}]^\\top$，其对应的标签是$y^{(i)}$。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"线性回归的基本元素 线性模型 当输入包含$d$个特征时，将预测结果$\\hat{y}$（通常使用“尖角”符号表示$y$的估计值）表示为： $$ \\hat{y} = w_1 x_1 + … + w_d x_d + b $$ 将所有特征放到向量$\\mathbf{x} \\in \\mathbb{R}^d$中，并将所有权重放到向量$\\mathbf{w} \\in \\mathbb{R}^d$中，可以用点积形式来简洁地表达模型，其中向量$\\mathbf{x}$对应于单个数据样本的特征： $$ \\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b $$ 用符号表示的矩阵$\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$，可以很方便地引用整个数据集的$n$个样本，其中，$\\mathbf{X}$的每一行是一个样本，每一列是一种特征。 对于特征集合$\\mathbf{X}$，预测值$\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$可以通过矩阵-向量乘法表示为： $$ {\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b $$ 无论使用什么手段来观察特征$\\mathbf{X}$和标签$\\mathbf{y}$，都可能会出现少量的观测误差，因此，即使确信特征与标签的潜在关系是线性的，也会加入一个噪声项来考虑观测误差带来的影响。 损失函数 损失函数（loss function）能够量化目标的实际值与预测值之间的差距。通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。回归问题中最常用的损失函数是平方误差函数。当样本$i$的预测值为$\\hat{y}^{(i)}$，其相应的真实标签为$y^{(i)}$时，平方误差可以定义为以下公式： $$ l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2 $$ 为了度量模型在整个数据集上的质量，我们需计算在训练集$n$个样本上的损失均值（也等价于求和）： $$ L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2 $$ 在训练模型时，我们希望寻找一组参数（$\\mathbf{w}’, b’$），这组参数能最小化在所有训练样本上的总损失。如下式： $$ \\mathbf{w}’, b’ = \\operatorname{argmin}_{\\mathbf{w}, b}\\ L(\\mathbf{w}, b) $$ 解析解 与其他大部分模型不同，线性回归的解可以用一个公式简单地表达出来， 这类解叫作解析解（analytical solution） 首先，将偏置$b$合并到参数$\\mathbf{w}$中，合并方法是在包含所有参数的矩阵中附加一列，上述预测问题是最小化$|\\mathbf{y} - \\mathbf{X}\\mathbf{w}|^2$。这在损失平面上只有一个临界点，这个临界点对应于整个区域的损失极小点。将损失关于$\\mathbf{w}$的导数设为0，得到解析解： 随机梯度下降 梯度下降（gradient descent）方法， 几乎可以优化所有深度学习模型。它通过不断地在损失函数递减的方向上更新参数来降低误差。 梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值） 关于模型参数的导数（在这里也可以称为梯度）。 但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须遍历整个数据集。 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本， 这种变体叫做小批量随机梯度下降（minibatch stochastic gradient descent）。 在每次迭代中，首先随机抽样一个小批量$\\mathcal{B}$，它是由固定数量的训练样本组成的，然后计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。最后，将梯度乘以一个预先确定的正数$\\eta$，并从当前参数的值中减掉。如： $$ (\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b) $$ 总结来说，算法步骤如下： 初始化模型参数的值，如随机初始化 从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤 $$\r\\begin{aligned} \\mathbf{w} \u0026\\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{\\mathbf{w}} l^{(i)}(\\mathbf{w}, b) = \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right),\\\\ b \u0026\\leftarrow b - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_b l^{(i)}(\\mathbf{w}, b) = b - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right). \\end{aligned}\r$$\r上述公式中的$\\mathbf{w}$和$\\mathbf{x}$都是向量，$|\\mathcal{B}|$表示每个小批量中的样本数，这也称为批量大小（batch size），$\\eta$表示学习率（learning rate）。批量大小和学习率的值通常是手动预先指定，而不是通过模型训练得到的。\r这些可以调整但不在训练过程中更新的参数称为超参数（hyperparameter）。调参（hyperparameter tuning）是选择超参数的过程，超参数通常是根据训练迭代结果来调整的，而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"正态分布 正态分布和线性回归之间的关系很密切。正态分布（normal distribution），也称为高斯分布（Gaussian distribution），简单的说，若随机变量$x$具有均值$\\mu$和方差$\\sigma^2$（标准差$\\sigma$），其正态分布概率密度函数如下： $$ p(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (x - \\mu)^2\\right) $$ def normal(x, mu, sigma): p = 1 / math.sqrt(2 * math.pi * sigma**2) return p * np.exp(-0.5 / sigma**2 * (x - mu)**2) 下面可视化正态分布： x = np.arange(-7, 7, 0.01) # 均值和标准差对 params = [(0, 1), (0, 2), (3, 1)] d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel='x', ylabel='p(x)', figsize=(4.5, 2.5), legend=[f'mean {mu}, std {sigma}' for mu, sigma in params]) 输出下面可视化： 改变均值会产生沿$x$轴的偏移，增加方差将会分散分布、降低其峰值。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"线性回归到深度网络 在上图所示的神经网络中，输入为$x_1, \\ldots, x_d$，因此输入层中的输入数（或称为特征维度）为$d$。网络的输出为$o_1$，因此输出层中的输出数是1。需要注意的是，输入值都是已经给定的，并且只有一个计算神经元。由于模型重点在发生计算的地方，所以通常我们在计算层数时不考虑输入层。所以上述神经网络的层数为1，可以将线性回归模型视为仅由单个人工神经元组成的神经网络，或称为单层神经网络。 对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连，这种变换称为全连接层（fully-connected layer）或称为稠密层（dense layer）。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"实现线性回归 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"生成数据集 假设生成一个包含1000个样本的数据集，每个样本包含从标准正态分布中采样的2个特征。所以数据集是一个矩阵$\\mathbf{X}\\in \\mathbb{R}^{1000 \\times 2}$。使用线性模型参数$\\mathbf{w} = [2, -3.4]^\\top$、$b = 4.2$和噪声项$\\epsilon$生成数据集及其标签： $$ \\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon $$ $\\epsilon$可以视为模型预测和标签时的潜在观测误差。在这里认为标准假设成立，即$\\epsilon$服从均值为0的正态分布。为了简化问题，我们将标准差设为0.01。python代码如下，其中$\\mathbf{X}$是随机生成的均值为0、标准差为1的num_examples行len(w)列的矩阵 def synthetic_data(w, b, num_examples): \"\"\"生成y=Xw+b+噪声\"\"\" X = torch.normal(0, 1, (num_examples, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"读取数据集 在下面的代码中，定义一个data_iter函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量。 每个小批量包含一组特征和标签。 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 这些样本是随机读取的，没有特定的顺序 random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] # 返回迭代器 batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, '\\n', y) break output: tensor([[ 0.3934, 2.5705], [ 0.5849, -0.7124], [ 0.1008, 0.6947], [-0.4493, -0.9037], [ 2.3104, -0.2798], [-0.0173, -0.2552], [ 0.1963, -0.5445], [-1.0580, -0.5180], [ 0.8417, -1.5547], [-0.6316, 0.9732]]) tensor([[-3.7623], [ 7.7852], [ 2.0443], [ 6.3767], [ 9.7776], [ 5.0301], [ 6.4541], [ 3.8407], [11.1396], [-0.3836]]) 当运行迭代时，会连续地获得不同的小批量，直至遍历完整个数据集。 上面实现的迭代对教学来说很好，但它的执行效率很低，可能会在实际问题上陷入麻烦。 例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。 在深度学习框架中实现的内置迭代器效率要高得多， 它可以处理存储在文件中的数据和数据流提供的数据。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"初始化模型参数 在我们开始用小批量随机梯度下降优化模型参数之前， 需要先有一些参数。 在下面的代码中，通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) 在初始化参数之后，需要更新这些参数，直到这些参数足够拟合数据。 每次更新都需要计算损失函数关于模型参数的梯度， 有了这个梯度，就可以向减小损失的方向更新每个参数。 这里使用 前面引入的自动微分来计算梯度。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义模型 定义模型，将模型的输入和参数同模型的输出关联起来。只需计算输入特征$\\mathbf{X}$和模型权重$\\mathbf{w}$的矩阵-向量乘法后加上偏置$b$。 def linreg(X, w, b): \"\"\"线性回归模型\"\"\" return torch.matmul(X, w) + b 补充：torch.mul() 、 torch.mm() 及torch.matmul()的区别 torch.mul(a,b) ：矩阵a和b对应位相乘，a和b的维度必须相等，比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵。 torch.mm(a,b)：矩阵a和b矩阵相乘，比如a的维度是(1, 2)，b的维度是(2, 3)，返回的就是(1, 3)的矩阵。限定二维，且不支持广播。 torch.matmul(a,b)：该操作取决于张量的维度 如果a、b都是一维的，则返回点积（标量）；torch.dot() 如果a、b都是二维的，则返回矩阵乘积；torch.mm() 如果a是二维的，b是一维的，则返回矩阵向量积；torch.mv() 如果a是一维的，b是二维的，那么为了矩阵相乘，在其维数前面加上1。在矩阵相乘之后，前面的维度被移除； 如果a和b都至少是一维的，并且至少有一个参数是N维的（其中N\u003e2），则返回一个成批矩阵乘法。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:4","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义损失函数 这里使用平方损失函数。 在实现中，需要将真实值y的形状转换为和预测值y_hat的形状相同。 def squared_loss(y_hat, y): \"\"\"均方损失\"\"\" return 1/2 * (y_hat - y.reshape(y_hat.shape)) ** 2 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:5","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义优化函数 这里使用小批量随机梯度下降法，该函数接受模型参数集合、学习速率和批量大小作为输入。每一步更新的大小由学习速率lr决定。 因为计算的损失是一个批量样本的总和，所以用梯度除掉批量大小（batch_size） 来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。 def sgd(params, lr, batch_size): \"\"\"小批量随机梯度下降\"\"\" with torch.no_grad(): # 定义函数的时候不用参与梯度计算 for param in params: param -= lr * param.grad / batch_size # 计算公式参照公式(8) param.grad.zero_() ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:6","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"训练 在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。 计算完损失后，我们开始反向传播，存储每个参数的梯度。 最后，我们调用优化算法sgd来更新模型参数。 概括步骤如下： 初始化参数 重复以下训练，直到完成 计算梯度$\\mathbf{g} \\leftarrow \\partial_{(\\mathbf{w},b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w}, b)$ 更新参数$(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\eta \\mathbf{g}$ 在每个迭代周期（epoch）中，使用data_iter函数遍历整个数据集， 并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设为3和0.03。 设置超参数很棘手，需要通过反复试验进行调整。 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X和y的小批量损失 # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起， # 并以此计算关于[w,b]的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}') output: epoch 1, loss 0.039428 epoch 2, loss 0.000156 epoch 3, loss 0.000053 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:7","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"使用深度学习框架简洁实现线性回归 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"生成数据集 import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"读取数据集 调用框架中现有的API来读取数据，将features和labels作为API的参数传递，并通过数据迭代器指定batch_size。 此外，布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据。使用深度学习框架读取数据可以帮你选好batch def load_array(data_arrays, batch_size, is_train=True): \"\"\"构造一个PyTorch数据迭代器\"\"\" dataset = data.TensorDataset(*data_arrays) return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) 使用data_iter的方式与我们在2.2节中使用data_iter函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。 与2.2节不同，这里使用iter构造Python迭代器，并使用next从迭代器中获取第一项。 next(iter(data_iter)) output: [tensor([[-0.3375, 0.3114], [ 0.4994, 0.8915], [ 0.7587, -0.9327], [-1.0011, 1.5100], [ 0.6620, 0.4560], [-0.4271, -0.7234], [ 1.2387, -0.4021], [ 1.7149, -1.5818], [ 0.5998, -1.4765], [ 1.4491, 0.4250]]), tensor([[ 2.4706], [ 2.1752], [ 8.8973], [-2.9463], [ 3.9697], [ 5.7897], [ 8.0600], [13.0047], [10.4142], [ 5.6422]])] ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义模型 对于标准深度学习模型，我们可以使用框架的预定义好的层。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。 我们首先定义一个模型变量net，它是一个Sequential类的实例。 Sequential类将多个层串联在一起。 当给定输入数据时，Sequential实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 在下面的例子中，我们的模型只包含一个层，因此实际上不需要Sequential。 但是由于以后几乎所有的模型都是多层的，在这里使用Sequential可以熟悉“标准的流水线”。 回顾1.3节Figure1-4中的单层网络架构， 这一单层被称为全连接层（fully-connected layer）， 因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。 在PyTorch中，全连接层在Linear类中定义。 将两个参数传递到nn.Linear中。 第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。 # nn是神经网络的缩写 from torch import nn net = nn.Sequential(nn.Linear(2, 1)) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"初始化模型参数 深度学习框架通常有预定义的方法来初始化参数，正如我们在构造nn.Linear时指定输入和输出尺寸一样， 现在我们能直接访问参数以设定它们的初始值。 我们通过net[0]选择网络中的第一层， 然后使用weight.data和bias.data方法访问参数。 我们还可以使用替换方法normal_和fill_来重写参数值。 net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) net[0].weight.data, net[0].bias.data output: (tensor([[0.0153, 0.0152]]), tensor([0.])) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:4","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义损失函数 计算均方误差使用的是MSELoss类，也称为平方$L_2$范数，默认情况下，它返回所有样本损失的平均值。 loss = nn.MSELoss() ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:5","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义优化算法 小批量随机梯度下降算法是一种优化神经网络的标准工具， PyTorch在optim模块中实现了该算法的许多变种。当实例化一个SGD实例时，要指定优化的参数 （可通过net.parameters()从模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置lr值，这里设置为0.03。 trainer = torch.optim.SGD(net.parameters(), lr=0.03) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:6","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"训练 在每个迭代周期里，将完整遍历一次数据集（train_data），不停地从中获取一个小批量的输入和相应的标签。对于每一个小批量，我们会进行以下步骤: 通过调用net(X)生成预测并计算损失l（前向传播）。 通过进行反向传播来计算梯度。 通过调用优化器来更新模型参数。 num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: l = loss(net(X) ,y) trainer.zero_grad() l.backward() # 反向传播计算梯度，pytorch已经做了sum()的操作 trainer.step() # 更新模型参数 l = loss(net(features), labels) print(f'epoch {epoch + 1}, loss {l:f}') output: epoch 1, loss 0.000184 epoch 2, loss 0.000099 epoch 3, loss 0.000098 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:7","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"softmax回归 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"分类问题 一种表示分类数据的简单方法：独热编码，它是一个向量，它的分量和类别一样多。类别对应的分量设置为1，其他所有分量设置为0。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"网络架构 为了估计所有可能类别的条件概率，需要一个有多个输出的模型，每个类别对应一个输出。为了解决线性模型的分类问题，我们需要和输出一样多的仿射函数（affine function），每个输出对应于它自己的仿射函数。在例子中，由于有4个特征和3个可能的输出类别，需要12个标量来表示权重（带下标的$w$），3个标量来表示偏置（带下标的$b$）。下面为每个输入计算三个未规范化的预测（logit）：$o_1$、$o_2$和$o_3$。 $$ \\begin{aligned} o_1 \u0026= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\\\ o_2 \u0026= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\\\ o_3 \u0026= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3. \\end{aligned} $$ 我们可以用神经网络图来描述这个计算过程，与线性回归一样，softmax回归也是一个单层神经网络。由于计算每个输出$o_1$、$o_2$和$o_3$取决于所有输入$x_1$、$x_2$、$x_3$和$x_4$，所以softmax回归的输出层也是全连接层。 通过向量形式表示为$\\mathbf{o} = \\mathbf{W} \\mathbf{x} + \\mathbf{b}$​，由此，已经将所有权重放到一个$3 \\times 4$矩阵中。对于给定数据样本的特征$\\mathbf{x}$，输出是由权重与输入特征进行矩阵-向量乘法再加上偏置$\\mathbf{b}$得到的。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"全连接层的参数开销 全连接层是“完全”连接的，可能有很多可学习的参数。具体来说，对于任何具有$d$个输入和$q$个输出的全连接层，参数开销为$\\mathcal{O}(dq)$，这个数字在实践中可能高得令人望而却步。幸运的是，将$d$个输入转换为$q$个输出的成本可以减少到$\\mathcal{O}(\\frac{dq}{n})$，其中超参数$n$可以由我们灵活指定，以在实际应用中平衡参数节约和模型有效性。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"softmax运算 我们不能将未规范化的预测$o$直接视作感兴趣的输出，因为将线性层的输出直接视为概率时存在一些问题：一方面，没有限制这些输出数字的总和为1；另一方面，根据输入的不同，它们可以为负值。 softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。为了完成这一目标，首先对每个未规范化的预测求幂，这样可以确保输出非负。 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和。如下式： $$ \\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o})\\quad \\text{其中}\\quad \\hat{y}_j = \\frac{\\exp(o_j)}{\\sum_k \\exp(o_k)} $$ softmax运算不会改变未规范化的预测$\\mathbf{o}$之间的大小次序，只会确定分配给每个类别的概率。 因此，在预测过程中仍然可以用下式来选择最有可能的类别。 $$ \\operatorname*{argmax}_j \\hat y_j = \\operatorname*{argmax}_j o_j $$ 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型（linear model）。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:4","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"小批量样本的矢量化 通常会对小批量样本的数据执行矢量计算。假设读取了一个批量的样本$\\mathbf{X}$，其中特征维度（输入数量）为$d$，批量大小为$n$。此外，假设在输出中有$q$个类别。那么小批量样本的特征为$\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$，权重为$\\mathbf{W} \\in \\mathbb{R}^{d \\times q}$，偏置为$\\mathbf{b} \\in \\mathbb{R}^{1\\times q}$。softmax回归的矢量计算表达式为： $$ \\begin{aligned} \\mathbf{O} \u0026= \\mathbf{X} \\mathbf{W} + \\mathbf{b}, \\ \\hat{\\mathbf{Y}} \u0026 = \\mathrm{softmax}(\\mathbf{O}). \\end{aligned} $$ 相对于一次处理一个样本，小批量样本的矢量化加快了$\\mathbf{X}和\\mathbf{W}$的矩阵-向量乘法。由于$\\mathbf{X}$中的每一行代表一个数据样本，那么softmax运算可以按行（rowwise）执行：对于$\\mathbf{O}$的每一行，我们先对所有项进行幂运算，然后通过求和对它们进行标准化。其中，$\\mathbf{X} \\mathbf{W} + \\mathbf{b}$的求和会使用广播机制，小批量的未规范化预测$\\mathbf{O}$和输出概率$\\hat{\\mathbf{Y}}$都是形状为$n \\times q$的矩阵。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:5","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"损失函数 使用最大似然估计。 对数似然 softmax函数给出了一个向量$\\hat{\\mathbf{y}}$，可以将其视为“对给定任意输入$\\mathbf{x}$的每个类的条件概率”。例如，$\\hat{y}_ 1=P(y=\\text{猫} \\mid \\mathbf{x})$。假设整个数据集${\\mathbf{X}, \\mathbf{Y}}$具有$n$个样本，其中索引$i$的样本由特征向量$\\mathbf{x}^{(i)}$和独热标签向量$\\mathbf{y}^{(i)}$组成。可以将估计值与实际值进行比较： $$ P(\\mathbf{Y} \\mid \\mathbf{X}) = \\prod_{i=1}^n P(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)}) $$ 根据最大似然估计，我们最大化$P(\\mathbf{Y} \\mid \\mathbf{X})$，相当于最小化负对数似然： $$ -\\log P(\\mathbf{Y} \\mid \\mathbf{X}) = \\sum_{i=1}^n -\\log P(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)}) = \\sum_{i=1}^n l(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)}) $$ 其中，对于任何标签$\\mathbf{y}$和模型预测$\\hat{\\mathbf{y}}$，损失函数为： $$ l(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{j=1}^q y_j \\log \\hat{y}_j $$ 上述的损失函数通常被称为交叉熵损失（cross-entropy loss）。由于$\\mathbf{y}$是一个长度为$q$的独热编码向量，所以除了一个项以外的所有项$j$都消失了。由于所有$\\hat{y}_j$都是预测的概率，所以它们的对数永远不会大于$0$。 softmax及其导数 将公式12代入损失公式17中，利用softmax的定义，得到： $$ \\begin{aligned} l(\\mathbf{y}, \\hat{\\mathbf{y}}) \u0026= - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\ \u0026= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j\\\\ \u0026= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j. \\end{aligned} $$ 考虑相对于任何未规范化的预测$o_j$的导数，得到： $$ \\partial_{o_j} l(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(\\mathbf{o})_j - y_j. $$ 换句话说，导数是softmax模型分配的概率与实际发生的情况（由独热标签向量表示）之间的差异。从这个意义上讲，这与在回归中看到的非常相似，其中梯度是观测值$y$和估计值$\\hat{y}$之间的差异。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:6","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"交叉熵损失 信息论的核心思想是量化数据中的信息内容。在信息论中，该数值被称为分布$P$的熵（entropy）。可以通过以下方程得到： $$ H[P] = \\sum_j - P(j) \\log P(j) $$ 信息论的基本定理之一指出，为了对从分布$p$中随机抽取的数据进行编码，至少需要$H[P]$“纳特（nat）”对其进行编码。“纳特”相当于比特（bit），但是对数底为$e$而不是2。因此，一个纳特是$\\frac{1}{\\log(2)} \\approx 1.44$比特。 交叉熵方法，常用来衡量两个概率的区别： $$ H(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)})=-\\sum_{j=1}^q y_j^{(i)}\\log \\hat{y}_j^{(i)} $$ ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:7","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"图像分类数据集 解析与实现 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:8","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"实现softmax回归 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"读取数据 参照4.8图像分类数据集 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"初始化模型参数 原始数据集中的每个样本都是$28 \\times 28$的图像，但这里展平每个图像，把它们看作长度为784的向量，并且暂时只把每个像素位置看作一个特征。因为我们的数据集有10个类别，所以网络输出维度为10，因此，权重将构成一个$784 \\times 10$的矩阵，偏置将构成一个$1 \\times 10$的行向量。 与线性回归一样，这里将使用正态分布初始化权重W，偏置初始化为0。 num_inputs = 784 num_outputs = 10 W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) b = torch.zeros(num_outputs, requires_grad=True) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义softmax操作 实现softmax由三步骤组成： 对每个项求幂（使用exp）； 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数； 将每一行除以其规范化常数，确保结果的和为1。 $$ \\mathrm{softmax}(\\mathbf{X})_ {ij} = \\frac{\\exp(\\mathbf{X}_ {ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})} $$ 分母或规范化常数，有时也称为配分函数（其对数称为对数-配分函数） def softmax(X): X_exp = torch.exp(X) partition = X_exp.sum(1, keepdim=True) return X_exp / partition # 这里应用了广播机制 使用上述softmax的例子如下： X = torch.normal(0, 1, (2, 5)) X_prob = softmax(X) X_prob, X_prob.sum(1) output: (tensor([[0.0370, 0.2185, 0.0159, 0.6100, 0.1186], [0.1783, 0.2683, 0.0036, 0.2175, 0.3323]]), tensor([1., 1.])) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义模型 定义softmax操作后，就可以实现softmax回归模型，下面的代码定义了输入如何通过网络映射到输出。(注意，将数据传递到模型之前，我们使用reshape函数将每张原始图像展平为向量。) def net(X): return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:4","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义损失函数 这里实现交叉熵损失函数，这可能是深度学习中最常见的损失函数，因为目前分类问题的数量远远超过回归问题的数量。 这里不使用Python的for循环迭代预测（这往往是低效的），而是通过一个运算符选择所有元素。我们创建一个数据样本y_hat，其中包含2个样本在3个类别的预测概率，以及它们对应的标签y。有了y，就知道在第一个样本中，第一类是正确的预测；而在第二个样本中，第三类是正确的预测。 然后使用y作为y_hat中概率的索引，选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。 y = torch.tensor([0, 2]) y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y_hat[[0, 1], y] output: tensor([0.1000, 0.5000]) 下面实现交叉熵损失函数 def cross_entropy(y_hat, y): return - torch.log(y_hat[range(len(y_hat)), y]) cross_entropy(y_hat, y) output: tensor([2.3026, 0.6931]) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:5","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"分类精度 分类精度即正确预测数量与总预测数量之比，精度通常是我们最关心的性能衡量标准，在训练分类器时几乎总会关注它。 首先，如果y_hat是矩阵，那么假定第二个维度存储每个类的预测分数。使用argmax获得每行中最大元素的索引来获得预测类别。 然后将预测类别与真实y元素进行比较。 由于等式运算符“==”对数据类型很敏感， 因此我们将y_hat的数据类型转换为与y的数据类型一致。 结果是一个包含0（错）和1（对）的张量。 最后，求和会得到正确预测的数量。 def accuracy(y_hat, y): \"\"\"计算预测正确的数量\"\"\" if len(y_hat.shape) \u003e 1 and y_hat.shape[1] \u003e 1: y_hat = y_hat.argmax(axis=1) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) 同样，对于任意数据迭代器data_iter可访问的数据集， 可以评估在任意模型net的精度。 def evaluate_accuracy(net, data_iter): \"\"\"计算在指定数据集上模型的精度\"\"\" if isinstance(net, torch.nn.Module): net.eval() # 将模型设置为评估模式 metric = Accumulator(2) # 正确预测数、预测总数 with torch.no_grad(): for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] 这里定义一个实用程序类Accumulator，用于对多个变量进行累加。 在上面的evaluate_accuracy函数中， 我们在Accumulator实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。 class Accumulator: \"\"\"在n个变量上累加\"\"\" def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:6","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"训练 在这里，我们重构训练过程的实现以使其可重复使用。 首先，我们定义一个函数来训练一个迭代周期。 updater是更新模型参数的常用函数，它接受批量大小作为参数。 它可以是d2l.sgd函数，也可以是框架的内置优化函数。 def train_epoch_ch3(net, train_iter, loss, updater): # 将模型设置为训练模式 if isinstance(net, torch.nn.Module): net.train() # 训练损失总和、训练准确度总和、样本数 metric = Accumulator(3) for X, y in train_iter: # 计算梯度并更新参数 y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # 使用PyTorch内置的优化器和损失函数 updater.zero_grad() l.mean().backward() updater.step() else: # 使用定制的优化器和损失函数 l.sum().backward() updater(X.shape[0]) metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 返回训练损失和训练精度 return metric[0] / metric[2], metric[1] / metric[2] 在展示训练函数的实现之前，我们定义一个在动画中绘制数据的实用程序类Animator， 它能够简化本书其余部分的代码。 class Animator: \"\"\"在动画中绘制数据\"\"\" def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale='linear', yscale='linear', fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1, figsize=(3.5, 2.5)): # 增量地绘制多条线 if legend is None: legend = [] d2l.use_svg_display() self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.axes = [self.axes, ] # 使用lambda函数捕获参数 self.config_axes = lambda: d2l.set_axes( self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # 向图表中添加多个数据点 if not hasattr(y, \"__len__\"): y = [y] n = len(y) if not hasattr(x, \"__len__\"): x = [x] * n if not self.X: self.X = [[] for _ in range(n)] if not self.Y: self.Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True) 接下来实现一个训练函数， 它会在train_iter访问到的训练数据集上训练一个模型net。 该训练函数将会运行多个迭代周期（由num_epochs指定）。 在每个迭代周期结束时，利用test_iter访问到的测试数据集对模型进行评估。 我们将利用Animator类来可视化训练进度。 def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=['train loss', 'train acc', 'test acc']) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) animator.add(epoch + 1, train_metrics + (test_acc,)) train_loss, train_acc = train_metrics assert train_loss \u003c 0.5, train_loss assert train_acc \u003c= 1 and train_acc \u003e 0.7, train_acc assert test_acc \u003c= 1 and test_acc \u003e 0.7, test_acc 作为一个从零开始的实现，我们使用小批量随机梯度下降来优化模型的损失函数，设置学习率为0.1。 lr = 0.1 def updater(batch_size): return d2l.sgd([W, b], lr, batch_size) 现在训练模型10个迭代周期，在这里迭代周期（num_epochs）和学习率（lr）都是可调节的超参数。 通过更改它们的值，我们可以提高模型的分类精度。 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:7","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"预测 现在训练已经完成，模型已经准备好对图像进行分类预测。 给定一系列图像，我们将比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）。 def predict_ch3(net, test_iter, n=6): \"\"\"预测标签（定义见第3章）\"\"\" for X, y in test_iter: break trues = d2l.get_fashion_mnist_labels(y) preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) titles = [true +'\\n' + pred for true, pred in zip(trues, preds)] d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) predict_ch3(net, test_iter) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:8","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"使用深度学习框架简洁实现softmax回归 ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:0","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"读取数据 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:1","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"初始化模型参数和定义模型 softmax回归的输出层是一个全连接层。 因此，为了实现我们的模型，只需在Sequential中添加一个带有10个输出的全连接层。注意，这里还是将$28 \\times 28$的图像，展平成长度为784的向量。 # PyTorch不会隐式地调整输入的形状。因此，我们在线性层前定义了展平层（flatten），来调整网络输入的形状 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:2","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"softmax实现和定义损失函数 重新审视softmax的实现 问题一：softmax函数$\\hat y_j = \\frac{\\exp(o_j)}{\\sum_k \\exp(o_k)}$，其中$\\hat y_j$是预测的概率分布。$o_j$是未规范化的预测$\\mathbf{o}$的第$j$个元素。如果$o_k$中的一些数值非常大，那么$\\exp(o_k)$可能大于数据类型容许的最大数字，即上溢（overflow）。这将使分母或分子变为inf（无穷大），最后得到的是0、inf或nan（不是数字）的$\\hat y_j$。在这些情况下，我们无法得到一个明确定义的交叉熵值。 解决这个问题的一个技巧是：在softmax计算之前，先从所有$o_k$中减去$\\max(o_k)$。这里可以看到每个$o_k$按常数进行的移动不会改变softmax的返回值： $$ \\hat y_j = \\frac{\\exp(o_j - \\max(o_k))}{\\sum_k \\exp(o_k - \\max(o_k))} $$ 问题二：在减法和规范化步骤之后，可能有些$o_j - \\max(o_k)$具有较大的负值。由于精度受限，$\\exp(o_j - \\max(o_k))$将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使$\\hat y_j$为零，并且使得$\\log(\\hat y_j)$的值为-inf。反向传播几步后，我们可能会发现自己面对一屏幕可怕的nan结果。 尽管我们要计算指数函数，但我们最终在计算交叉熵损失时会取它们的对数。通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。如下面的等式所示，我们避免计算$\\exp(o_j - \\max(o_k))$，而可以直接使用$o_j - \\max(o_k)$，因为$\\log(\\exp(\\cdot))$被抵消了。 $$ \\begin{aligned} \\log{(\\hat y_j)} \u0026 = \\log\\left( \\frac{\\exp(o_j - \\max(o_k))}{\\sum_k \\exp(o_k - \\max(o_k))}\\right) \\\\ \u0026 = \\log{(\\exp(o_j - \\max(o_k)))}-\\log{\\left( \\sum_k \\exp(o_k - \\max(o_k)) \\right)} \\\\ \u0026 = o_j - \\max(o_k) -\\log{\\left( \\sum_k \\exp(o_k - \\max(o_k)) \\right)}. \\end{aligned} $$ 我们也希望保留传统的softmax函数，以备我们需要评估通过模型输出的概率。但是，我们没有将softmax概率传递到损失函数中，而是在交叉熵损失函数中传递未规范化的预测，并同时计算softmax及其对数。 定义损失函数 loss = nn.CrossEntropyLoss(reduction='none') ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:3","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"定义优化算法 这里使用学习率为0.1的小批量随机梯度下降作为优化算法。 trainer = torch.optim.SGD(net.parameters(), lr=0.1) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:4","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"训练 num_epochs = 10 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ","date":"2023-10-29","objectID":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:6:5","tags":["d2l","pytorch"],"title":"3 线性神经网络","uri":"/3-%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"categories":["动手学深度学习"],"content":"数据操作 访问元素，子区间访问为开区间，如 1: 3 的含义是[1, 3)左闭右开，:: 3 的含义是从头到尾跳 3 个访问 Figure 1-1 数据操作\r使用 arange 创建一个行向量 x x = torch.arange(12) output: tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) 可以通过张量的 shape 属性来访问张量（沿每个轴的长度）的形状 x.shape output: torch.Size([12]) 如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。因为这里在处理的是一个向量，所以它的 shape 与它的 size 相同 x.numel() output: 12 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数，此外我们可以通过-1来调用此自动计算出维度的功能。 即可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)，因为知道宽度或者高度后，另一个维度会被自动计算得到 X = x.reshape(3, 4) output:tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 使用全0、全1、其他常量，或者从特定分布中随机采样的数字，来初始化矩阵 torch.zeros((2, 3, 4)) output:tensor([[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]]) torch.ones((2, 3, 4)) output:tensor([[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]]) torch.randn(3, 4) output:tensor([[-0.0135, 0.0665, 0.0912, 0.3212], [ 1.4653, 0.1843, -1.6995, -0.3036], [ 1.7646, 1.0450, 0.2457, -0.7732]]) 通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值 torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) output: tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"运算符 对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算 x = torch.tensor([1.0, 2, 4, 8]) y = torch.tensor([2, 2, 2, 2]) x + y, x - y, x * y, x / y, x ** y # **运算符是求幂运算 output:(tensor([ 3., 4., 6., 10.]), tensor([-1., 0., 2., 6.]), tensor([ 2., 4., 8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1., 4., 16., 64.])) torch.exp(x) output: tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03]) 将多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。我们只需要提供张量列表，并给出沿哪个轴连结。 X = torch.arange(12, dtype=torch.float32).reshape(3,4) Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1) output:(tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [ 2., 1., 4., 3.], [ 1., 2., 3., 4.], [ 4., 3., 2., 1.]]), tensor([[ 0., 1., 2., 3., 2., 1., 4., 3.], [ 4., 5., 6., 7., 1., 2., 3., 4.], [ 8., 9., 10., 11., 4., 3., 2., 1.]])) 通过逻辑运算符构建二元张量，以及对张量中所有元素求和 X == Y output:tensor([[False, True, False, True], [False, False, False, False], [False, False, False, False]]) X.sum() output:tensor(66.) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:1","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"广播机制 即使张量形状不同，我们仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作，这种机制的工作方式如下： 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状； 对生成的数组执行按元素操作。 a = torch.arange(3).reshape((3, 1)) b = torch.arange(2).reshape((1, 2)) a, b output:(tensor([[0], [1], [2]]), tensor([[0, 1]])) a + b output:tensor([[0, 1], [1, 2], [2, 3]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:2","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"索引和切片 可以用[-1]选择最后一个元素，可以用[1:3]选择第二个和第三个元素 X = torch.arange(12, dtype=torch.float32).reshape(3,4) X[-1], X[1:3] output:(tensor([ 8., 9., 10., 11.]), tensor([[ 4., 5., 6., 7.], [ 8., 9., 10., 11.]])) 我们想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。 X[0:2, :] = 12 X output:tensor([[12., 12., 12., 12.], [12., 12., 12., 12.], [ 8., 9., 10., 11.]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:3","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"节省内存 运行一些操作可能会导致为新结果分配内存，用Python的id()函数演示了这一点 before = id(Y) Y = Y + X id(Y) == before output: False 执行原地操作非常简单，可以使用切片表示法将操作的结果分配给先前分配的数组，也可以用+= Z = torch.zeros_like(Y) print('id(Z):', id(Z)) Z[:] = X + Y print('id(Z):', id(Z)) output:id(Z): 135358378815744 id(Z): 135358378815744 X += Y ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:4","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"转换为其他Python对象 将深度学习框架定义的张量转换为NumPy张量ndarray很容易，使用numpy()；反之也同样容易，使用torch.tensor() A = X.numpy() B = torch.tensor(A) type(A), type(B) output:(numpy.ndarray, torch.Tensor) 将大小为1的张量转换为Python标量，可以调用item函数或Python的内置函数 a = torch.tensor([3.5]) a, a.item(), float(a), int(a) output:(tensor([3.5000]), 3.5, 3.5, 3) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:1:5","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"数据预处理 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:2:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"读取数据集 从CSV文件中加载原始数据集 import pandas as pd data = pd.read_csv(data_file) print(data) output:NumRooms Alley Price 0 NaN Pave 127500 1 2.0 NaN 106000 2 4.0 NaN 178100 3 NaN NaN 140000 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:2:1","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"处理缺失值 为了处理缺失的数据，典型的方法包括插值法和删除法， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。 在这里，我们将考虑插值法，通过位置索引iloc，我们将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。对于inputs中缺少的数值，我们用同一列的均值替换“NaN”项。 inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2] inputs = inputs.fillna(inputs.mean()) print(inputs) output:NumRooms Alley 0 3.0 Pave 1 2.0 NaN 2 4.0 NaN 3 3.0 NaN 对于inputs中不能取均值的类别值或离散值，我们将“NaN”视为一个类别。由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。 dummy_na : bool, default False Add a column to indicate NaNs, if False NaNs are ignored. inputs = pd.get_dummies(inputs, dummy_na=True) print(inputs) output:NumRooms Alley_Pave Alley_nan 0 3.0 1 0 1 2.0 0 1 2 4.0 0 1 3 3.0 0 1 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:2:2","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"转换为张量格式 现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式 X = torch.tensor(inputs.to_numpy(dtype=float)) y = torch.tensor(outputs.to_numpy(dtype=float)) X, y output:(tensor([[3., 1., 0.], [2., 0., 1.], [4., 0., 1.], [3., 0., 1.]], dtype=torch.float64), tensor([127500., 106000., 178100., 140000.], dtype=torch.float64)) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:2:3","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"线性代数 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"标量 Figure 3-1 标量\r标量由只有一个元素的张量表示 import torch x = torch.tensor(3.0) y = torch.tensor(2.0) x + y, x * y, x / y, x**y output: (tensor(5.), tensor(6.), tensor(1.5000), tensor(9.)) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:1","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"向量 点乘（若两向量正交，则下面式子等于0）： $$ a^Tb=\\sum_{i}{a_i}{b_i} $$ 向量可以被视为标量值组成的列表，可以通过索引来访问任一元素 x = torch.arange(4) output: tensor([0, 1, 2, 3]) x[3] output: tensor(3) 调用Python的内置len()函数来访问张量的长度，当用张量表示一个向量（只有一个轴）时，我们也可以通过.shape属性访问向量的长度。 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数） len(x) output: 4 x.shape output: torch.Size([4]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:2","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"矩阵 一般采用F范数进行矩阵范数的计算： 对称矩阵$A_{ij}=A_{ji}$，反对称矩阵$A_{ij}=-A_{ji}$ 正交矩阵： 所有行都相互正交 所有行都有单位长度 $U , with, \\sum_{j}{U_{ij}U_{kj}}$ 可以写成$UU^T=1$ 置换矩阵（是正交矩阵）：$P ; where; P_{ij}=1 ;if ;and ;only ;if ;j=\\pi(i)$ 特征向量和特征值：$Ax=\\lambda x$ 不被矩阵改变方向的向量$x$是特征向量，对称矩阵总是可以找到特征向量 特征值是$\\lambda$ 通过指定两个分量m和n来创建一个形状为m×n的矩阵 A = torch.arange(20).reshape(5, 4) output: tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]) 矩阵的转置 A.T output: tensor([[ 0, 4, 8, 12, 16], [ 1, 5, 9, 13, 17], [ 2, 6, 10, 14, 18], [ 3, 7, 11, 15, 19]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:3","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"张量 与矩阵相似构建张量 X = torch.arange(24).reshape(2, 3, 4) output: tensor([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) 给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量 A = torch.arange(20, dtype=torch.float32).reshape(5, 4) B = A.clone() # 通过分配新内存，将A的一个副本分配给B A, A + B output: (tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.], [16., 17., 18., 19.]]), tensor([[ 0., 2., 4., 6.], [ 8., 10., 12., 14.], [16., 18., 20., 22.], [24., 26., 28., 30.], [32., 34., 36., 38.]])) 两个矩阵的按元素乘法称为Hadamard积（Hadamard product）（数学符号⊙） $$ \\mathbf{A} \\odot \\mathbf{B} = \\left[ \\begin{matrix} a_{11} b_{11} \u0026 a_{12} b_{12} \u0026 \\dots \u0026 a_{1n} b_{1n} \\\\ a_{21} b_{21} \u0026 a_{22} b_{22} \u0026 \\dots \u0026 a_{2n} b_{2n} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ a_{m1} b_{m1} \u0026 a_{m2} b_{m2} \u0026 \\dots \u0026 a_{mn} b_{mn} \\end{matrix} \\right] $$ A * B output: tensor([[ 0., 1., 4., 9.], [ 16., 25., 36., 49.], [ 64., 81., 100., 121.], [144., 169., 196., 225.], [256., 289., 324., 361.]]) 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘 a = 2 X = torch.arange(24).reshape(2, 3, 4) a + X, (a * X).shape output: (tensor([[[ 2, 3, 4, 5], [ 6, 7, 8, 9], [10, 11, 12, 13]], [[14, 15, 16, 17], [18, 19, 20, 21], [22, 23, 24, 25]]]), torch.Size([2, 3, 4])) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:4","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"降维 可以指定张量沿哪一个轴来通过求和降低维度 A = torch.arange(20, dtype=torch.float32).reshape(5, 4) output: tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.], [16., 17., 18., 19.]] A_sum_axis0 = A.sum(axis=0) A_sum_axis0, A_sum_axis0.shape output: (tensor([40., 45., 50., 55.]), torch.Size([4])) A_sum_axis1 = A.sum(axis=1) A_sum_axis1, A_sum_axis1.shape output: (tensor([6., 22., 38., 54., 70.]), torch.Size([5])) 沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和 A.sum(axis=[0, 1]) # 结果和A.sum()相同 output: tensor(190.) 一个与求和相关的量是平均值（mean或average），同样，计算平均值的函数也可以沿指定轴降低张量的维度 A.mean(), A.sum() / A.numel() output: (tensor(9.5000), tensor(9.5000)) A.mean(axis=0), A.mean(axis=1), A.sum(axis=0) / A.shape[0] output: (tensor([ 8., 9., 10., 11.]), tensor([ 1.5000, 5.5000, 9.5000, 13.5000, 17.5000]), tensor([ 8., 9., 10., 11.])) 有时在调用函数来计算总和或均值时保持轴数不变会很有用 sum_A = A.sum(axis=1, keepdims=True) output: tensor([[ 6.], [22.], [38.], [54.], [70.]]) 由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播将A除以sum_A A / sum_A output: tensor([[0.0000, 0.1667, 0.3333, 0.5000], [0.1818, 0.2273, 0.2727, 0.3182], [0.2105, 0.2368, 0.2632, 0.2895], [0.2222, 0.2407, 0.2593, 0.2778], [0.2286, 0.2429, 0.2571, 0.2714]]) 沿某个轴计算A元素的累积总和 A.cumsum(axis=0) output: tensor([[ 0., 1., 2., 3.], [ 4., 6., 8., 10.], [12., 15., 18., 21.], [24., 28., 32., 36.], [40., 45., 50., 55.]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:5","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"点积 给定两个向量$\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^d$，它们的点积（dot product）$\\mathbf{x}^\\top\\mathbf{y}$（或$\\langle\\mathbf{x},\\mathbf{y}\\rangle$）是相同位置的按元素乘积的和：$\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$。也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积 x = torch.arange(4, dtype=torch.float32) y = torch.ones(4, dtype=torch.float32) x, y, torch.dot(x, y) output: (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.)) torch.sum(x * y) output: tensor(6.) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:6","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"矩阵-向量积和乘法 矩阵向量积 在代码中使用张量表示矩阵-向量积，我们使用mv函数。 当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。A的列维数（沿轴1的长度）必须与x的维数（其长度）相同 A.shape, x.shape, torch.mv(A, x) output: (torch.Size([5, 4]), torch.Size([4]), tensor([ 14., 38., 62., 86., 110.])) 矩阵乘法 使用mm函数对矩阵做矩阵乘法 B = torch.ones(4, 3) torch.mm(A, B) output: tensor([[ 6., 6., 6.], [22., 22., 22.], [38., 38., 38.], [54., 54., 54.], [70., 70., 70.]]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:7","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"范数 在线性代数中，向量范数是将向量映射到标量的函数$f$。 给定任意向量$x$，向量范数要满足一些属性： 如果我们按常数因子$\\alpha$缩放向量的所有元素， 其范数也会按相同常数因子的绝对值缩放： $$ f(\\alpha \\mathbf{x}) = |\\alpha| f(\\mathbf{x}) $$ 熟悉的三角不等式： $$ f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y}) $$ 范数必须是非负的，且范数最小为0，当且仅当向量全由0组成： $$ f(\\mathbf{x}) \\geq 0 $$ $L_2$范数是向量元素平方和的平方根：$||\\mathbf{x}||_ 2 = \\sqrt{\\sum_{i=1}^n x_i^2}$，其中，在$L_2$范数中常常省略下标$2$，也就是说$||\\mathbf{x}||$等同于$||\\mathbf{x}||_2$。 在代码中，我们可以按如下方式计算向量的$L_2$范数： u = torch.tensor([3.0, -4.0]) torch.norm(u) output: tensor(5.) $L_1$范数它表示为向量元素的绝对值之和：$||\\mathbf{x}||_ 1 = \\sum_{i=1}^n \\left|x_i \\right|$，与$L_2$范数相比，$L_1$范数受异常值的影响较小。为了计算$L_1$范数，将绝对值函数和按元素求和组合起来： torch.abs(u).sum() output: tensor(7.) $L_2$范数和$L_1$范数都是更一般的$L_p$范数的特例：$||\\mathbf{x}||_ p = \\left(\\sum_{i=1}^n \\left|x_i \\right|^p \\right)^{1/p}$。 类似于向量的$L_2$范数，矩阵$\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$的Frobenius范数是矩阵元素平方和的平方根：$||\\mathbf{X}||_ F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$，Frobenius范数满足向量范数的所有性质，它就像是矩阵形向量的$L_2$范数。调用以下函数将计算矩阵的Frobenius范数： torch.norm(torch.ones((4, 9))) output: tensor(6.) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:3:8","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"微积分 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:4:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"导数和微分 可以将拟合模型的任务分解为两个关键问题： 优化（optimization）：用模型拟合观测数据的过程 泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型 给定$y=f(x)$，其中$x$和$y$分别是函数$f$的自变量和因变量。以下表达式是等价的： $$ f’(x) = y’ = \\frac{dy}{dx} = \\frac{df}{dx} = \\frac{d}{dx} f(x) = Df(x) = D_x f(x) $$ 其中符号$\\frac{d}{dx}$和$D$是微分运算符，表示微分操作，可以使用以下规则来对常见函数求微分： $DC = 0$（$C$是一个常数） $Dx^n = nx^{n-1}$ $De^x = e^x$ $D\\ln(x) = 1/x$ 假设函数$f$和$g$都是可微的，$C$是一个常数，则： 常数相乘法则：$$\\frac{d}{dx} [Cf(x)] = C \\frac{d}{dx} f(x),$$ 加法法则：$$\\frac{d}{dx} [f(x) + g(x)] = \\frac{d}{dx} f(x) + \\frac{d}{dx} g(x),$$ 乘法法则：$$\\frac{d}{dx} [f(x)g(x)] = f(x) \\frac{d}{dx} [g(x)] + g(x) \\frac{d}{dx} [f(x)],$$ 除法法则：$$\\frac{d}{dx} \\left[\\frac{f(x)}{g(x)}\\right] = \\frac{g(x) \\frac{d}{dx} [f(x)] - f(x) \\frac{d}{dx} [g(x)]}{[g(x)]^2}.$$ ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:4:1","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"偏导数 在深度学习中，函数通常依赖于许多变量。因此，我们需要将微分的思想推广到多元函数上。为了计算$\\frac{\\partial y}{\\partial x_i}$，我们可以简单地将$x_1, \\ldots, x_{i-1}, x_{i+1}, \\ldots, x_n$看作常数，并计算$y$关于$x_i$的导数。对于偏导数的表示，以下是等价的： $$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial f}{\\partial x_i} = f_{x_i} = f_i = D_i f = D_{x_i} f $$ ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:4:2","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"梯度 可以连结一个多元函数对其所有变量的偏导数，以得到该函数的梯度（gradient）向量。具体而言，设函数$f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$的输入是一个$n$维向量$\\mathbf{x}=[x_1,x_2,\\ldots,x_n]^\\top$，并且输出是一个标量。函数$f(\\mathbf{x})$相对于$\\mathbf{x}$的梯度是一个包含$n$个偏导数的向量： $$ \\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\bigg[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\bigg]^\\top $$ 其中$\\nabla_{\\mathbf{x}} f(\\mathbf{x})$通常在没有歧义时被$\\nabla f(\\mathbf{x})$取代。 假设$\\mathbf{x}$为$n$维向量，在微分多元函数时经常使用以下规则: 对于所有$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$，都有$\\nabla_{\\mathbf{x}} \\mathbf{A} \\mathbf{x} = \\mathbf{A}^\\top$ 对于所有$\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$，都有$\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} = \\mathbf{A}$ 对于所有$\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，都有$\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = (\\mathbf{A} + \\mathbf{A}^\\top)\\mathbf{x}$ $\\nabla_{\\mathbf{x}} |\\mathbf{x} |^2 = \\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{x} = 2\\mathbf{x}$ 同样，对于任何矩阵$\\mathbf{X}$，都有$\\nabla_{\\mathbf{X}} |\\mathbf{X} |_F^2 = 2\\mathbf{X}$。 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:4:3","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"链式法则 然而，上面方法可能很难找到梯度，因为在深度学习中，多元函数通常是复合（composite）的， 所以难以应用上述任何规则来微分这些函数。 幸运的是，链式法则可以被用来微分复合函数。 先考虑单变量函数。假设函数$y=f(u)$和$u=g(x)$都是可微的，根据链式法则： $$ \\frac{dy}{dx} = \\frac{dy}{du} \\frac{du}{dx} $$ 当函数具有任意数量的变量的情况时，假设可微分函数$y$有变量$u_1, u_2, \\ldots, u_m$，其中每个可微分函数$u_i$都有变量$x_1, x_2, \\ldots, x_n$。对于任意$i = 1, 2, \\ldots, n$，链式法则给出： $$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial u_1} \\frac{\\partial u_1}{\\partial x_i} + \\frac{\\partial y}{\\partial u_2} \\frac{\\partial u_2}{\\partial x_i} + \\cdots + \\frac{\\partial y}{\\partial u_m} \\frac{\\partial u_m}{\\partial x_i} $$ ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:4:4","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"自动微分 自动求导的两种模式：正向累积和反向累积（反向传播） 正向累积：计算复杂度是O(n)，用来计算一个变量的梯度；内存复杂度是O(1) 反向累积：计算复杂度是O(n)，n是操作子个数；内存复杂度是O(n)，因为需要存储正向的所有中间结果 假设我们想对函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导 import torch x = torch.arange(4.0) x output: tensor([0., 1., 2., 3.]) 在我们计算$y$关于$\\mathbf{x}$的梯度之前，需要一个地方来存储梯度，使用requires_grad_(True)。一个标量函数关于向量$\\mathbf{x}$的梯度是向量，并且与$\\mathbf{x}$具有相同的形状，而标量函数关于向量$\\mathbf{x}$的导数是向量，且其形状是向量$\\mathbf{x}$的转置 x.requires_grad_(True) # 等价于x=torch.arange(4.0,requires_grad=True) x.grad # 默认值是None y = 2 * torch.dot(x, x) y output: tensor(28., grad_fn=\u003cMulBackward0\u003e) 通过调用反向传播函数来自动计算y关于x每个分量的梯度 y.backward() x.grad output: tensor([2., 2., 2., 2.]) 根据手算可得，函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于$\\mathbf{x}$的梯度应为$4\\mathbf{x}$ 如果要计算$\\mathbf{x}$的另一个函数，需要首先清楚梯度的值 # 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值 x.grad.zero_() y = x.sum() y.backward() x.grad output: tensor([1., 1., 1., 1.]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:5:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"非标量变量的反向传播 当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵，但我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和 x.grad.zero_() y = x * x # 等价于y.backward(torch.ones(len(x))) y.sum().backward() x.grad output: tensor([0., 2., 4., 6.]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:5:1","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"分离计算 有时希望将某些计算移动到记录的计算图之外，例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。若想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。 x.grad.zero_() y = x * x u = y.detach() z = u * x z.sum().backward() x.grad == u output: tensor([True, True, True, True]) 由于记录了y的计算结果，可以随后在y上调用反向传播， 得到y=x*x关于的x的导数，即2*x。 x.grad.zero_() y.sum().backward() x.grad == 2 * x output: tensor([True, True, True, True]) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:5:2","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"Python控制流的梯度计算 使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），仍然可以计算得到的变量的梯度 def f(a): b = a * 2 while b.norm() \u003c 1000: b = b * 2 if b.sum() \u003e 0: c = b else: c = 100 * b return c # 随机标量 a = torch.randn(size=(), requires_grad=True) d = f(a) d.backward() a.grad == d / a output: tensor(True) ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:5:3","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"categories":["动手学深度学习"],"content":"概率 ","date":"2023-10-29","objectID":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/:6:0","tags":["d2l","pytorch"],"title":"2 预备知识","uri":"/2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"}]